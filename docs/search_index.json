[["index.html", "PLS Data Exploration Book Chapter 1 Introduction", " PLS Data Exploration Book Lauren Kremer 2025-01-31 Chapter 1 Introduction This book records the workflow that was used for the FEF DOC poster presented at AGU 2024 description: This book describes the workflow of the PLS FEF DOC analysis "],["about.html", "1.1 About", " 1.1 About This book currently documents the development of the PLS-SEM model used to identify a paths of variable influence in our watersheds. This analysis can provide insights into the direct and indirect influences within our system. By estimating path coefficients and measuring the strength and direction of relationships, PLS-SEM models help infer the structural connections among ‘latent variables’, guiding our understanding of complex causal mechanisms within the system. While PLS-SEM doesn’t prove causation, it suggests plausible paths of influence within the system. PLS-SEM connects observed variables to their underlying concepts (latent variables). It combines factor analysis (which reduces reducing a large number of variables into a smaller set of factors, like PCA) with regression. However, unlike traditional regression, which focuses on directly observed variables, PLS-SEM aims to maximize the explained variance in the dependent variables and handles complex, indirect relationships and interactions in the system by evaluating two models at once. The measurement model evaluates relationships between our observed variables and underlying concepts (latent variables). For example, in our dataset, we might consider different measures of a latent variable ‘topography’ as watershed aspect, slope, elevation and indices derived from those measurements like the ‘total wetness index’ (indicators). We can simultaneously determine the relationships among our ‘indicators’ and between indicators and our latent variables while also evaluating the structural model, which looks for relationships between the latent variables. It is robust with non-normal data and ‘small’ samples. It can be used for both exploratory and confirmatory analysis. Here is a simple 2-min video: "],["usage.html", "1.2 Usage", " 1.2 Usage Addition of precipitation and runoff: - This section will grow to include all data management files if Python can be included Correlations plots: data exploration: - Includes the results of PARAFAC analysis. Reviews correlations among compound measures and fluorescence indices. Partial least squares - SEM: - a demo using FEF data to review terms and observe a basic model Testing iterations of the PLS_SEM FEF - multiple models in different combinations of indicator and latent variables. "],["addition-of-precipitation-and-runoff-data.html", "Chapter 2 Addition of precipitation and runoff data", " Chapter 2 Addition of precipitation and runoff data This script will eventually be moved to an earlier chapter in the workflow once the data management and collection chapters are added to this book. For the time being, this generates a .csv that is imported to chapter 4. Inputs used in this script are inputsim_dh1_year and fool_input_year csvs that are generated from snowmelt models. Scripts are found in models_analysis/WECOH_deadhorse/1_precip/scripts/5_SNOTEL.SWE.Model.Deadhorse.LK.Rmd and a similar path for the Fool Creek WECOH workflow. Runoff and snowmelt are modeled for both, one model for each side of the East S. Louis catchament. Therefore Deadhorse estimations are also applied to Lexen in the PLS analysis. This is a summary of the precip data added to the PLS test iteration workflow. Blue represents the snowpack, orange is input. Each point represents the 3 day rolling average of each sample at the time it was collected. "],["relating-parafac-components-to-fef-watersheds-correlations-plots.html", "Chapter 3 Relating PARAFAC components to FEF watersheds: Correlations plots", " Chapter 3 Relating PARAFAC components to FEF watersheds: Correlations plots This script is an exploratory data visualization and testing multivariate procedures using the results of the 3-component PARAFAC model as response variables. PARAFAC methods: The corrected Excitation-emission matrix (EEM) were merged into a three-dimensional matrix and analyzed via the multivariate data analysis technique parallel factor analysis (PARAFAC) (Murphy et al. 2013). PARAFAC is a statistical tool used to decompose trilinear data arrays to identify and quantify independent underlying signals or ’components’ (Bro, 1997). DOM components were resolved using PARAFAC analysis and the package staRdom (Pucher et al. 2019) in statistical software R (version). The three-component model was validated through split-half analysis, which generates independent models from subsamples of the dataset (Murphy et al. 2014). The similarity between these models was assessed using Tucker’s congruence coefficient, with all values exceeding 0.98. This fit required removing 8 outliers, the 8 points with the greatest and inordinate leverage. Following validation, the 3 component PARAFAC model (table) was uploaded to the OpenFluor spectral database (Murphy et al, 2014) to identify spectrally similar components across other studies. Records in the database matching our components with a Tucker congruence exceeding (check 0.98) were reviewed to improve interpretation component sources and functions. The model is then exported to a dataframe containing the sum of loadings (intensities) for each sample, and the total and relative loadings for each component is merged with a summary dataframe that contains DOC concentration, as well as landcover, discharge and topographical data for each sample. # Generate a discharge column that is normalized by the area of the respective watershed. merged_df&lt;- merged_df%&gt;% mutate(Qm3_s = replace_na(Qm3_s, 0.005)) merged_df$discharge_m2 &lt;- merged_df$Qm3_s/merged_df$area_m merged_df$Input.mm_m2 &lt;- merged_df$Input.mm/merged_df$area_m merged_df$snowpack_m2 &lt;- merged_df$snowpack_3day_avg/merged_df$area_m # Transform aspect from degrees to radians merged_df$aspect_mean_rad &lt;- merged_df$aspect_mean*pi/180 "],["parafac-results-summary-figures.html", "3.1 PARAFAC results summary figures:", " 3.1 PARAFAC results summary figures: Emission-Excitation matrices for the 3 components identified by the 3 component PARAFAC model. Components 1 and 2 correspond with peaks for humic components, while component 3 is protein-like. "],["structure.html", "3.2 Structure:", " 3.2 Structure: There are a few ways we can group and explore this data. We can observe the PARAFAC components as fractions of the total fluorescence, i.e., the DOC ‘community’ structure. We can also review the DOC normalized fluorescence intensity of each component. This could help us better examine lability of DOC and how much fluorescence signal is produced per unit of carbon and differences in overall DOM reactivity (i.e., does a larger proportion of DOM fluoresce in some samples relative to others). This section will look first at distributions, correlations and PCA with relative loadings as the response variable, then follow a similar workflow with normalized DOC as the response. "],["relative-loadings.html", "3.3 1. Relative loadings", " 3.3 1. Relative loadings Relative loadings for each sample (i.e., loading for each component/total loading for the sample in the 3 component model). This tells us how much of each component contributes to the total fluorescence of that particular sample. 3.3.1 Box plots - Relative loadings Boxplots are visualizing relative loadings (component loading/total loading for the sample). These are not normalized by DOC concentration. This allows for comparisons between sites with varying DOC concentrations while avoiding the confounding effects of variations in DOC concentration. (i.e., regardless of the overall fluorescence intensity or DOC concentration) 3.3.1.1 Protein-like Figure 3.1: Figure. Box plots showing the relationships between the sample proportion of PARAFAC component 3 (protein-like) and watershed. dh,dhn and dhs = Deadhorse, fc = Fool Creek. Horizontal bars indicate sample median, asterisks indicate sample mean. Whiskers (vertical lines) extend to the most extreme data point which is no more than range times the interquartile range from the box 3.3.1.2 Humic Figure 3.2: Figure. Box plots showing the relationships between the sample proportion of PARAFAC component 1 (humic-type) and watershed. dh,dhn and dhs = Deadhorse, fc = Fool Creek Figure 3.3: Figure. Box plots showing the relationships between the sample proportion of PARAFAC component 2 (humic-type) and watershed. dh,dhn and dhs = Deadhorse, fc = Fool Creek mean_df &lt;- merged_df %&gt;% mutate(watershed_group = case_when( str_detect(watershed, &quot;dh&quot;) ~ &quot;Deadhorse&quot;, TRUE ~ as.character(watershed) # Ensures other watershed names are retained as characters )) %&gt;% group_by(watershed_group) %&gt;% summarise(mean_value = mean(relative_load_comp_1, na.rm = TRUE), .groups = &#39;drop&#39;) merged_merged_df &lt;- merged_df %&gt;% mutate(watershed_group = case_when( str_detect(watershed, &quot;dh&quot;) ~ &quot;Deadhorse&quot;, TRUE ~ as.character(watershed) # Ensures other watershed names are retained as characters )) # Create the box plot for relative_load_comp_3 across watersheds plot &lt;- ggplot(merged_merged_df, aes(x = watershed_group, y = relative_load_comp_3)) + geom_boxplot(fill = &quot;skyblue&quot;, outlier.color = &quot;black&quot;, outlier.size = 2) + # Box plot with outliers geom_point(data = mean_df, aes(x = watershed_group, y = mean_value), color = &quot;darkorange&quot;, size = 3, shape = 8) + # Add mean as a point theme_minimal() + labs(x = &quot;Watershed&quot;, y = &quot;Proportion of sample\\ncontaining protein-like component&quot;, title = &quot;Box Plot of component 3 with Mean Indicator Across Watersheds&quot;) + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12), # Adjust x-axis tick label size axis.text.y = element_text(size = 16), # Adjust y-axis tick label size axis.title.x = element_text(size = 16), # Adjust x-axis title size axis.title.y = element_text(size = 16)) + # Adjust y-axis title size theme(axis.text.x = element_text(angle = 45, hjust = 1)) + # Rotate x-axis labels theme(axis.text.x = element_text(angle = 45, hjust = 1)) + # Rotate x-axis labels annotate(&quot;text&quot;, x = 5.1, y = 0.29, label = &quot;Mean&quot;, color = &quot;darkorange&quot;, size = 5, hjust = 0) # Print the plot print(plot) # Select only the necessary columns fred_df &lt;- merged_df %&gt;% dplyr::select(&quot;watershed&quot;, &quot;relative_load_comp_1&quot;, &quot;relative_load_comp_2&quot;, &quot;relative_load_comp_3&quot;) # Reshape data to long format long_df &lt;- fred_df %&gt;% mutate(watershed_group = case_when( str_detect(watershed, &quot;dh&quot;) ~ &quot;Deadhorse&quot;, TRUE ~ as.character(watershed) # Retains original watershed names )) %&gt;% pivot_longer(cols = starts_with(&quot;relative_load_comp_&quot;), names_to = &quot;component&quot;, values_to = &quot;value&quot;) %&gt;% mutate(watershed_group = str_replace(watershed_group, &quot;lexen&quot;, &quot;Lexen&quot;))%&gt;% mutate(watershed_group = str_replace(watershed_group, &quot;fc&quot;, &quot;Fool&quot;)) # Compute means for each watershed and component mean_df &lt;- long_df %&gt;% group_by(watershed_group, component) %&gt;% summarise(mean_value = mean(value, na.rm = TRUE), .groups = &quot;drop&quot;) plot &lt;- ggplot(long_df, aes(x = watershed_group, y = value, fill = component)) + geom_boxplot(outlier.color = &quot;black&quot;, outlier.size = 2) + # Box plot with outliers geom_point(data = mean_df, aes(x = watershed_group, y = mean_value), color = &quot;darkorange&quot;, size = 3, shape = 8, inherit.aes = FALSE) + # Mean points theme_minimal() + labs(x = &quot;Watershed&quot;, y = &quot;Proportion of sample\\ncontaining indicated component&quot;, title = &quot;Box Plots of PARAFAC Components Across Watersheds&quot;) + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12), # Adjust x-axis labels axis.text.y = element_text(size = 14), axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14), strip.text = element_blank()) + # Remove facet labels facet_wrap(~component, scales = &quot;fixed&quot;) + # Same Y-axis scale across facets scale_fill_manual(values = c(&quot;relative_load_comp_1&quot; = &quot;skyblue&quot;, &quot;relative_load_comp_2&quot; = &quot;lightcoral&quot;, &quot;relative_load_comp_3&quot; = &quot;mediumseagreen&quot;)) + # Custom colors annotate(&quot;text&quot;, x = 5.1, y = max(long_df$value, na.rm = TRUE) * 0.9, label = &quot;Mean&quot;, color = &quot;darkorange&quot;, size = 5, hjust = 0) # Print the plot print(plot) # Save the plot as a .png ggsave(filename = &quot;images/comp_ws_boxplot.png&quot;, plot = plot, width = 8, height = 6, dpi = 300) ####By REACH Figure 3.4: Figure. Box plots showing the relationships between the sample proportion of PARAFAC component 1 (humic-type) and reach. dh= Deadhorse, lx = Lexen Creek, fc = Fool Creek 3.3.2 Spearman’s While Pearson’s correlation assumes linear relationships and normal distributions among variables, and Spearman assumptions are that data is monotonic (distribution consistently increases or decreases), most of our data for both response and explanatory variables are skewed or bimodal but uni-directional. Explanatory variable distributions: Figure 3.5: Figure. Plotting original distribution of response variables Figure 3.6: Figure. Plotting original distribution of explanatory variables Explanatory variable distributions: Figure 3.7: Figure. Plotting original distribution of explanatory variables Explanatory variable distributions: Figure 3.8: Figure. Plotting original distribution of explanatory variables 3.3.3 Pearson correlation matrices (scaled data) - Relative loadings 3.3.3.1 All samples with EEMs If matrices are in a purple gradient, then the plot includes all dates. If green, then the plot represents a subset of dates By looking at these, we are answering: “How does DOC composition shift with different watershed features?” 3.3.3.1.1 Landcover - all EEMS Figure 3.9: Figure. Combined plot showing the relationships between relative loadings of 3 PARAFAC components and landcover characteristics for all samples with EEMs data (July 2021- Oct 1, 2022). Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. This figure indicates that: - The humic fraction of the fluorescing DOM decreases with high percentages of tundra, and short canopy. - The humic fraction increases with increasing watershed coverage with forest canopy between 6 and 10m, and increasing landcover classified as cut or regenerating. - There are low but significant correlations between humic fractions and % catchment coverage by beetle-kill, meadows and old forest. Humic fractions increase slightly with % Beetle Kill and decrease with increased meadow or old forest coverage. - Protein-like fractions of the fluorescing DOM decrease with high percentages of cut or regenerating forest, and canopy between 6 and 10m, - but increase with increased coverage by short canopy (&lt;5m) and Tundra. - Significant but weaker correlations indicate that protein-like fractions increase with increasing meadow and old forest coverage. 3.3.3.1.2 PARAFAC and EEM ratios - all EEMS ## RStudioGD ## 2 This figure show significant correlations between common matrix-derived indices and PARAFAC component compositions. Relative loads show opposite correlations with indices, while DOC normalized values show similar trends (e.g., Fluorescence Index has a negative relationship with all normalized values.) 3.3.3.1.3 Topo and moisture - all EEMS Figure 3.10: Figure. Combined plot showing the relationships between relative loadings of 3 PARAFAC components and topographic or moisture characteristics for all samples with EEMs data (July 2021- Oct 1, 2022). Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. This figure indicates that: - humic fraction of the fluorescing DOM increase with increasing discharge, watershed area, the distance that allochthonous water travels before reaching the stream channel (dist to streams mean), and increased watershed moisture (as indicated by NDMI and TWI). - Humic fractions decrease with increasing watershed slope. - Protein-like fractions of the fluorescing DOM increase with increasing slope - and decrease with increasing Q, watershed area, increasing moisture indices, and increased mean distance to the stream channel. 3.3.3.1.4 Ions - all EEMS Figure 3.11: Figure. Combined plot showing the relationships between relative loadings of 3 PARAFAC components and DOC (mg/L), and ions (mg/L) for all samples with EEMs data (July 2021- Oct 1, 2022). Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. This figure indicates that: - humic fraction of the fluorescing DOM increase with increasing DOM, sodium, potassium (K) and fluoride (F) concentration). - Humic fractions decrease with increasing Ca+, Mg, and nitrate (NO3). - Protein-like fractions of the fluorescing DOM increase with increasing Ca+, Mg, and nitrate (NO3 - and decrease with increasing DOM, sodium, potassium (K) and fluoride (F) concentration). These correlations suggest that seasonal hydrological fluxes, rather than direct causation, drive changes in humic and protein fractions. Humic fractions are higher during periods of snowmelt and runoff compared to baseflow conditions. Snowmelt leads to elevated DOC as it is ‘flushed’ from the catchments. Correlations among ions and topographical or landcover features suggest co-correlation rather than causation…. 3.3.4 Spearman’s correlation figure for AGU poster 2024 Figure 3.12: Figure. Correlations of the relationships between potential response variables (e.g., DOM characteristics from EEMs and PARAFAC analysis) and predictor variables (hydrological, topographical, landcover or chemical characteristics of each watersample subcatchment) for all samples with EEMs data (July 2021- Oct 1, 2022). Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. 3.3.5 Spearman’s correlation figure for POSTER2 Figure 3.13: Figure. Combined plot showing the relationships between relative loadings of 3 PARAFAC components and DOC (mg/L), and ions (mg/L) for all samples with EEMs data (July 2021- Oct 1, 2022). Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. 3.3.5.1 Summer subset 2022 (mid-June to mid July) 3.3.5.1.1 Landcover - summer 2022 Figure 3.14: Figure. Combined plot showing the relationships between relative loadings of 3 PARAFAC components and landcover characteristics for EEMs samples collected between June 10 to July 15, 2022, which includes a synoptic sampling. Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. This figure indicates that humic fraction of the fluorescing DOM increase with high percentages of tundra, and short canopy. Protein-like fractions of the fluorescing DOM increase with high percentages of cut or regenerating forest, and canopy between 6 and 10m. 3.3.5.1.2 Topography and Moisture Figure 3.15: Figure. Combined plot showing the relationships between relative loadings of 3 PARAFAC components and topographic or moisture characteristics for EEMs samples collected between June 10 to July 15, 2022, which includes a synoptic sampling. Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. This figure indicates that humic fraction of the fluorescing DOM increase with increasing discharge, the distance that allochthonous water travels before reaching the stream channel, and increased watershed moisture. Humic fractions decrease with watershed slope. Protein-like fractions of the fluorescing DOM increase with increasing slope and decrease with increasing Q, increasing moisture indices, and increased mean distance to the stream channel. 3.3.5.1.3 Ions - summer 2022 (mid-June to mid July) Figure 3.16: Figure. Combined plot showing the relationships between relative loadings of 3 PARAFAC components and DOC (mg/L), and ions (mg/L) EEMs samples collected between June 10 to July 15, 2022, which includes a synoptic sampling. Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. 3.3.6 Hydrograph - Fool Creek fractions with hydrograph Figure 3.17: Figure. relative loadings over time from Fool Creek outlet stream site only. Component 1 (humic) appears to increase with discharge while the fraction of Component 2 (humic) and Component 3 (protein-like) decrease during peak flow 3.3.7 Hydrograph - Fool Creek with NO3 3.3.8 Hydrograph - Fool Creek with DOC 3.3.9 Hydrograph - Lexen Creek fractions with hydrograph Figure 3.18: Figure. relative loadings over time from Lexen Creek outlet stream site only. Component 1 (humic) appears to increase with discharge while the fraction of Component 2 (humic) and Component 3 (protein-like) decrease during peak flow 3.3.10 Hydrograph - Lexen Creek DOC 3.3.11 Hydrograph - Lexen Creek DOC with NO3 3.3.12 Hydrograph - Deadhorse Main fractions with hydrograph Figure 3.19: Figure. relative loadings over time from Deadhorse outlet stream site only. Component 1 (humic) appears to increase with discharge while the fraction of Component 2 (humic) and Component 3 (protein-like) decrease during peak flow 3.3.13 Hydrograph - Deadhorse Main DOC with NO3 hydrograph Figure 3.20: Figure. relative loadings over time from Deadhorse outlet stream site only. Component 1 (humic) appears to increase with discharge while the fraction of Component 2 (humic) and Component 3 (protein-like) decrease during peak flow 3.3.14 Hydrograph - Deadhorse NORTH fractions with hydrograph Figure 3.21: Figure. relative loadings over time from Deadhorse NORTH outlet stream site only. Component 1 (humic) appears to increase with discharge while the fraction of Component 2 (humic) and Component 3 (protein-like) decrease during peak flow 3.3.15 Hydrograph - Deadhorse SOUTH DOC with NO3 # Combine specific watersheds into one category plot_df &lt;- sample_vege_fluro_topo %&gt;% mutate( datetime = mdy_hm(datetime), combined_watershed = case_when( watershed %in% c(&#39;dh&#39;, &#39;dhn&#39;, &#39;dhs&#39;) ~ &#39;dh_combined&#39;, # Combine &#39;dh&#39;, &#39;dhn&#39;, &#39;dhs&#39; TRUE ~ as.character(watershed) # Keep other watersheds as they are ) ) %&gt;% filter(position == &#39;stream&#39;) %&gt;% dplyr::select(datetime, NO3_mg.l, combined_watershed) %&gt;% drop_na(NO3_mg.l) # Plot NO3_mg.l by combined watershed gg &lt;- ggplot(plot_df, aes(x = datetime, y = NO3_mg.l, color = combined_watershed)) + # Add points for NO3_mg.l geom_point(size = 2.5) + # Add lines for NO3_mg.l geom_line() + # Add the hydrograph as a line in the background geom_line( data = dhhydrograph, aes( x = TMSTAMP, y = Q..cfs. / max(Q..cfs., na.rm = TRUE) * max(plot_df$NO3_mg.l, na.rm = TRUE) ), color = &quot;blue&quot;, linetype = &quot;solid&quot;, alpha = 0.5 ) + # Add secondary y-axis for the hydrograph scale_y_continuous( name = &quot;Concentration (mg/L)&quot;, sec.axis = sec_axis( trans = ~ . * (max(dhhydrograph$Q..cfs., na.rm = TRUE) / max(plot_df$NO3_mg.l, na.rm = TRUE)), name = &quot;Discharge (cfs)&quot; ) ) + # Styling theme_minimal() + labs( x = &quot;Date&quot;, y = &quot;NO3 Concentration (mg/L)&quot;, color = &quot;Watershed&quot;, title = &quot;Time Series of NO3 Concentration with Hydrograph (Combined dh, dhn, dhs)&quot; ) + theme( legend.position = &quot;bottom&quot;, strip.text = element_text(size = 10) ) # Display the plot print(gg) ## Warning: Removed 2 rows containing missing values or values outside the scale range (`geom_point()`). ## Warning: Removed 2 rows containing missing values or values outside the scale range (`geom_line()`). # Combine specific watersheds into one category plot_df &lt;- sample_vege_fluro_topo %&gt;% mutate( datetime = mdy_hm(datetime), combined_watershed = case_when( watershed %in% c(&#39;dh&#39;, &#39;dhn&#39;, &#39;dhs&#39;) ~ &#39;dh_combined&#39;, # Combine &#39;dh&#39;, &#39;dhn&#39;, &#39;dhs&#39; TRUE ~ as.character(watershed) # Keep other watersheds as they are ) ) %&gt;% filter(position == &#39;stream&#39;) %&gt;% dplyr::select(datetime, NO3_mg.l, combined_watershed) %&gt;% drop_na(NO3_mg.l) # Plot NO3_mg.l by combined watershed gg &lt;- ggplot(plot_df, aes(x = datetime, y = NO3_mg.l, color = combined_watershed)) + # Add points for NO3_mg.l geom_point(size = 2.5) + # Add lines for NO3_mg.l geom_line() + # Add the hydrograph as a line in the background geom_line( data = dhhydrograph, aes( x = TMSTAMP, y = Q..cfs. / max(Q..cfs., na.rm = TRUE) * max(plot_df$NO3_mg.l, na.rm = TRUE) ), color = &quot;blue&quot;, linetype = &quot;solid&quot;, alpha = 0.5 ) + # Add secondary y-axis for the hydrograph scale_y_continuous( name = &quot;Concentration (mg/L)&quot;, sec.axis = sec_axis( trans = ~ . * (max(dhhydrograph$Q..cfs., na.rm = TRUE) / max(plot_df$NO3_mg.l, na.rm = TRUE)), name = &quot;Discharge (cfs)&quot; ) ) + # Styling theme_minimal() + labs( x = &quot;Date&quot;, y = &quot;NO3 Concentration (mg/L)&quot;, color = &quot;Watershed&quot;, title = &quot;Time Series of NO3 Concentration with Hydrograph (Combined dh, dhn, dhs)&quot; ) + theme( legend.position = &quot;bottom&quot;, strip.text = element_text(size = 10) ) # Display the plot print(gg) ## Warning: Removed 2 rows containing missing values or values outside the scale range (`geom_point()`). ## Warning: Removed 2 rows containing missing values or values outside the scale range (`geom_line()`). 3.3.16 Data preparation for multivariate statistical analysis - dimension reduction techniques So we have a lot of variables, both response and explanatory, so we’ll want to reduce the dimensionality and complexity of the data by using ordination methods that find best fitting components in multi-dimensional space. To decide on a method, we need to understand the relationships among our variables to decide if and how we want to deal with collinearity. In another workbook (.ipynb), we have seen collinearity between independent variables e.g. (slope and percent_Old.Forest). Multicollinearity can be a problem when fitting regression models as it makes it harder to interpret our coefficients. Using VIF (Variance Inflation Factor) we can explore collinearity between our independent variables. Interpreting the results: If the VIF is less than 5, multicollinearity is typically not a concern. If VIF is between 5 and 10, there may be some moderate multicollinearity. If VIF is greater than 10, multicollinearity is likely a serious issue, and you may want to consider removing or transforming variables. 3.3.16.1 Multicollinearity ## doc_mg.l na_mg.l nh4_mg.l K_mg.l ## 2.773422 3.836951 1.776459 3.174043 ## Mg_mg.l Ca_mg.l F_mg.l Cl_mg.l ## 4.692212 6.557847 1.805230 2.401802 ## NO3_mg.l area_km Qm3_s percent_1.5 ## 2.222772 5.890812 1.183790 1810.657331 ## percent_6.10 percent_11.15 slope_mean aspect_mean ## 1026.835121 559.358510 8.325173 6.799846 ## ndmi_raster_mean ndvi_raster_mean disttostreams_mean percent_Beetle.kill ## 12.823483 6.024474 4.572233 167.668833 ## percent_Old.Forest percent_cut.regenerating percent_Tundra distance.to.outlet ## 135.680021 40.850573 113.775325 10.038567 So given that we have a lot of mulitcollinearity, we can systematically remove variables that are non-essential or redundant: ## area_km slope_mean aspect_mean ndmi_raster_mean ## 1.821739 3.137001 4.071621 4.811914 ## ndvi_raster_mean disttostreams_mean percent_Beetle.kill percent_Old.Forest ## 3.600649 3.860539 84.413534 77.730036 ## percent_cut.regenerating percent_Tundra ## 22.383774 54.771818 But ultimately we have several variables contributing to a high VIF that are all important to our question. Therefore, we can try RDA and PCA as a dimension reduction technique, assuming we remove some of the most redundant variables. This should transform() the predictors into a smaller set of uncorrelated PCs (components) that still explain most of the variance. 3.3.16.2 Distributions and standardization To perform RDA and PCA, explanatory and response variables must be centered, standardized, transformed or normalized So these are all quantitative variables with different units and numerical ranges. Standardization transforms the variables so they have a mean of zero and a standard deviation of one. Let’s view the scaled distributions of standardized explanatory variables: Figure 3.22: Figure. Checking out the distribution of explanatory variables Now we will check the distributions of our response variables Figure 3.23: Figure. Checking out the distribution of response variables Our response variables are both right and left-skewed unimodal. We may need to make the data more symmetrical or approximately normal, This can ensure that they contribute equally to the analysis and RDA assumes linear relationships between variables. But these may be be close enough to approximately normal once they are standardized/z-scored (subtracts the mean and divides by the standard deviation for each variable): The scales are similar, the units are the same. Let’s move forward for now. Initial exploration with PCA Q² evaluates how well the model can predict unseen data based on the selected number of components. A higher Q² value indicates better predictive performance. Commonly, a Q² value greater than 0.095 is considered an acceptable threshold for a good predictive model. None of our components have Q² total greater than 0.095. This suggests that the PLS model may not have enough predictive power to explain the relationship between the response variables and explanatory variables, based on cross-validation. We know the relationships between individual response variables and explanatory variables are strong. PLS does not assume normality of the data, though scaling does seem to help the Q2. From the tutorial: “We now set a grid of values - thin at the start, but also restricted to a small number of genes for a parsimonious model, which we will test for each of the two components in the tune.spls() function, using the MAE criterion.” So, in simpler terms, I think this means this piece of code is tuning a partial least squares (PLS) regression model using cross-validation to find the best number of variables to include in the model. I want to include all response variables at this point, so this is adapted from the tutorial: ## Warning: &lt;anonymous&gt;: ... may be used in an incorrect context: ## spls(X = X, Y = Y, keepX = c(choice.keepX, keepX), keepY = c(choice.keepY, ## keepY), ncomp = comp, mode = mode, ...) ## Warning: &lt;anonymous&gt;: ... may be used in an incorrect context: ## spls(X = X, Y = Y, keepX = c(choice.keepX, keepX), keepY = c(choice.keepY, ## keepY), ncomp = comp, mode = mode, ...) ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 PC6 PC7 PC8 PC9 PC10 ## Standard deviation 2.1860 1.4916 1.3046 1.1224 0.91363 0.68046 0.6681 0.36959 0.3305 0.18584 ## Proportion of Variance 0.3982 0.1854 0.1418 0.1050 0.06956 0.03859 0.0372 0.01138 0.0091 0.00288 ## Cumulative Proportion 0.3982 0.5836 0.7254 0.8304 0.89997 0.93856 0.9758 0.98714 0.9962 0.99911 ## PC11 PC12 ## Standard deviation 0.10306 8.348e-11 ## Proportion of Variance 0.00089 0.000e+00 ## Cumulative Proportion 1.00000 1.000e+00 ## Warning: The SGCCA algorithm did not converge 3.3.17 RDA (Redundancy Analysis) https://r.qcbs.ca/workshop10/book-en/redundancy-analysis.html Similar to PCA, but RDA is a constrained method that requries two datasets, one for response variables (e.g., PARAFAC component fractions) and one for explanatory variables (watershed characteristics) RDA identifies the portion of the variation in the response dataset that can be explained by the explanatory variables. So this tells us how much of the variability in the response variables is explained by the predictors. 3.3.17.1 All data - Workflow hidden except results for comparison to other subsets In the summary tables, the ‘Importance of components’ tells us the eigenvalues and their contributions to the variance for RDA components 1-3 and the PCs 1-3. ie. an eigenvalue represents the amount of variance explained by each component. Higher eigenvalues indicate that the component explains a larger portion of the total variance in the data. Then the Proportion Explained is the fraction of the total variance explained by each component. So at RDA1: Proportion Explained, we might see 0.32, which means RDA explains approximately 32% of the totalvariance. Then the cumulative Proportion tells us how much more of the variation is explianed as we add more components. Summary of ‘ALL SAMPLES’ RDA ## ## Call: ## rda(formula = standardized_resp ~ aspect_mean + twi_mean + ndvi_raster_mean + disttostreams_mean + percent_Beetle.kill + percent_Old.Forest + percent_cut.regenerating + area_km + Qm3_s, data = explanatory_standardized, na.action = na.exclude) ## ## Partitioning of variance: ## Inertia Proportion ## Total 3.000 1.0000 ## Constrained 1.063 0.3544 ## Unconstrained 1.937 0.6456 ## ## Eigenvalues, and their contribution to the variance ## ## Importance of components: ## RDA1 RDA2 PC1 PC2 ## Eigenvalue 1.0295 0.03353 1.6401 0.29686 ## Proportion Explained 0.3432 0.01118 0.5467 0.09895 ## Cumulative Proportion 0.3432 0.35436 0.9010 1.00000 ## ## Accumulated constrained eigenvalues ## Importance of components: ## RDA1 RDA2 ## Eigenvalue 1.0295 0.03353 ## Proportion Explained 0.9685 0.03154 ## Cumulative Proportion 0.9685 1.00000 3.3.17.2 Streams only - workflow retained but hidden results shown for comparison among other analyses scaled: Summary of ‘STREAMS ONLY’ RDA ## ## Call: ## rda(formula = standardized_resp ~ aspect_mean + twi_mean + ndvi_raster_mean + disttostreams_mean + percent_Beetle.kill + percent_Old.Forest + percent_cut.regenerating + area_km + Qm3_s, data = explanatory_standardized, na.action = na.exclude) ## ## Partitioning of variance: ## Inertia Proportion ## Total 3.000 1.0000 ## Constrained 1.472 0.4905 ## Unconstrained 1.528 0.5095 ## ## Eigenvalues, and their contribution to the variance ## ## Importance of components: ## RDA1 RDA2 PC1 PC2 ## Eigenvalue 1.4418 0.029811 1.3070 0.22145 ## Proportion Explained 0.4806 0.009937 0.4357 0.07382 ## Cumulative Proportion 0.4806 0.490522 0.9262 1.00000 ## ## Accumulated constrained eigenvalues ## Importance of components: ## RDA1 RDA2 ## Eigenvalue 1.4418 0.02981 ## Proportion Explained 0.9797 0.02026 ## Cumulative Proportion 0.9797 1.00000 The Eigenvalues, and their contribution to the variance table provides a broader comparison of RDA and PCA results, while the Accumulated constrained eigenvalues shows the effectiveness of RDA components in explaining the variance in the context of the response variables. With both response and explanatory variables scaled as z-scores using scale(), we get an RDA that explains much of the constrained variance (97%). Let’s look at the coefficients associated with the variables in RDA1. They indicate the strength and direction of the relationship between each explanatory variable and the RDA1 component. 3.3.17.3 Summer synoptic: Shows entire workflow to derive best fitting RDA ## ## Call: ## rda(formula = standardized_resp ~ aspect_mean + twi_mean + ndvi_raster_mean + disttostreams_mean + percent_Beetle.kill + percent_Old.Forest + percent_cut.regenerating + area_km + Qm3_s, data = explanatory_standardized, na.action = na.exclude) ## ## Partitioning of variance: ## Inertia Proportion ## Total 3.0000 1.0000 ## Constrained 2.1704 0.7235 ## Unconstrained 0.8296 0.2765 ## ## Eigenvalues, and their contribution to the variance ## ## Importance of components: ## RDA1 RDA2 PC1 PC2 ## Eigenvalue 2.0177 0.15266 0.5835 0.24610 ## Proportion Explained 0.6726 0.05089 0.1945 0.08203 ## Cumulative Proportion 0.6726 0.72347 0.9180 1.00000 ## ## Accumulated constrained eigenvalues ## Importance of components: ## RDA1 RDA2 ## Eigenvalue 2.0177 0.15266 ## Proportion Explained 0.9297 0.07034 ## Cumulative Proportion 0.9297 1.00000 Significance testing: ## Permutation test for rda under reduced model ## Permutation: free ## Number of permutations: 999 ## ## Model: rda(formula = standardized_resp ~ aspect_mean + twi_mean + ndvi_raster_mean + disttostreams_mean + percent_Beetle.kill + percent_Old.Forest + percent_cut.regenerating + area_km + Qm3_s, data = explanatory_standardized, na.action = na.exclude) ## Df Variance F Pr(&gt;F) ## Model 9 2.17041 8.7208 0.001 *** ## Residual 30 0.82959 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We can also test the significance of each canonical axis with by = “axis”. Recall that these axes represent the variation in explanatory variables in fewer dimensions. ## Permutation test for rda under reduced model ## Forward tests for axes ## Permutation: free ## Number of permutations: 999 ## ## Model: rda(formula = standardized_resp ~ aspect_mean + twi_mean + ndvi_raster_mean + disttostreams_mean + percent_Beetle.kill + percent_Old.Forest + percent_cut.regenerating + area_km + Qm3_s, data = explanatory_standardized, na.action = na.exclude) ## Df Variance F Pr(&gt;F) ## RDA1 1 2.01775 89.9920 0.001 *** ## RDA2 1 0.15266 6.8087 0.777 ## Residual 37 0.82959 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 or we can test the significance of each variable: ## Permutation test for rda under reduced model ## Terms added sequentially (first to last) ## Permutation: free ## Number of permutations: 999 ## ## Model: rda(formula = standardized_resp ~ aspect_mean + twi_mean + ndvi_raster_mean + disttostreams_mean + percent_Beetle.kill + percent_Old.Forest + percent_cut.regenerating + area_km + Qm3_s, data = explanatory_standardized, na.action = na.exclude) ## Df Variance F Pr(&gt;F) ## aspect_mean 1 0.09478 3.4274 0.054 . ## twi_mean 1 1.06887 38.6529 0.001 *** ## ndvi_raster_mean 1 0.20600 7.4496 0.010 ** ## disttostreams_mean 1 0.43123 15.5942 0.002 ** ## percent_Beetle.kill 1 0.01110 0.4013 0.649 ## percent_Old.Forest 1 0.21447 7.7558 0.010 ** ## percent_cut.regenerating 1 0.00007 0.0025 0.998 ## area_km 1 0.10385 3.7556 0.047 * ## Qm3_s 1 0.04004 1.4478 0.230 ## Residual 30 0.82959 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 A variable may appear to have a strong influence or a high loading but not be statistically significant. This could be due to the variable being strongly correlated with the main gradient in the data but lacking statistical robustness (due to multicollinearity?). Variables like this might capture major trends in the data but don’t significantly improve the fit of the model when tested. This could mean that they are redundant or that the sample size is too small to detect their significance. Less influential but statistically significant means they account for a relatively small but non-random portion of the total variation. Might not be the primary drivers of variation, but they can be still be important to our understanding of secondary influences/trends. Figure 3.24: Figure. RDA1 loadings tell us the direction and strength between each explantory variable and the RDA1 component. Interpreting loadings for RDA1: Recall that there are three response variables here, each will have a loading that indicates its correlation with RDA1. Humic components 1 and 2 will have similar loadings (positive and negative) on RDA1, where the protein-like component will have the opposite loading. In the biplot, this should be visible as response variable vectors pointing in opposite directions. Figure 3.25: Figure. RDA biplot 3.3.18 PCA - All data Figure 3.26: Figure. ## Eigenvalue Variance_Explained Cumulative_Variance ## comp 1 4.334490879 39.40446254 39.40446 ## comp 2 1.889328111 17.17571010 56.58017 ## comp 3 1.539675922 13.99705383 70.57723 ## comp 4 0.983282106 8.93892823 79.51615 ## comp 5 0.731481403 6.64983093 86.16599 ## comp 6 0.654949112 5.95408284 92.12007 ## comp 7 0.434764212 3.95240193 96.07247 ## comp 8 0.226075080 2.05522800 98.12770 ## comp 9 0.149561730 1.35965209 99.48735 ## comp 10 0.052174173 0.47431066 99.96166 ## comp 11 0.004217272 0.03833884 100.00000 Although PC1 and PC2 explain a lot of the variance and most pubs focus on these, PC3 contributes a non-trivial amount of variance (14%). Together, the first three components explain the majority of the total variance, which (I think) is a better threshold for interpretation than &lt;50%. Let’s see. Visualize the PC1 loadings to see what our important drivers are: In this case, PC1 might represent a gradient related to DOC lability or stability across the landscape (e.g., a transition from microbial activity-driven DOC production in low slopes, southern aspects, more moist sub-watersheds, to more labile DOC driven by hydrological transport in older forests due to higher slopes, northern aspects and drier sub-watersheds. Subwatersheds with older forests tend to be on higher slopes, northern aspects, which receive less solar radiation (cooler, less microbial activity). These also retain snow for longer, sustaining humic inputs through the falling limb (we might see this in Lexen)? A lot more detail is applied to this below. …BUT, PCA is unsupervised and doesn’t directly consider the response variable. So how well does PC1 explain the variability of the first PARAFAC component (humic)?. Let’s look at PC1 in 2-D space by plotting it against our response variable to see how PC1 correlates with the sample fraction of Humic Component1. We can get a sense of the strength and direction of the relationship: Meh. Explore correlations between the first 3 PCs and the response variable: ## [,1] ## Dim.1 0.4663184 ## Dim.2 -0.1561253 ## Dim.3 0.1694781 Lets fit a linear model with the first few components as predictors: ## ## Call: ## lm(formula = relative_load_comp_1 ~ Dim.1 + Dim.2 + Dim.3, data = pca_scores) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.30978 -0.03651 0.01655 0.05372 0.31329 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.597820 0.005858 102.057 &lt; 2e-16 *** ## Dim.1 0.023549 0.002814 8.370 5.19e-15 *** ## Dim.2 -0.011942 0.004262 -2.802 0.00550 ** ## Dim.3 0.014360 0.004721 3.042 0.00262 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.09056 on 235 degrees of freedom ## Multiple R-squared: 0.2706, Adjusted R-squared: 0.2612 ## F-statistic: 29.05 on 3 and 235 DF, p-value: 5.149e-16 Conclusions Component1: The small coefficients, combined with the relatively low R-squared value, suggest that even though the relationships are significant, they might not be strong enough to drive substantial changes in relative_load_comp_1. I can increase the amount of variability by remove more variables from the PCA, but this still does not drastically improve the relationship between PC1 and PARAFAC component 1. Let’s look at Components 2 and 3 in the same fashion. It could be that Component 1 is driven by the fractions of 2 and 3…? COMPONENT 2 Explore correlations between the first 3 PCs and the response variable: ## [,1] ## Dim.1 0.46306607 ## Dim.2 -0.03276488 ## Dim.3 0.31992048 Lets fit a linear model with the first few components as predictors: ## ## Call: ## lm(formula = relative_load_comp_2 ~ Dim.1 + Dim.2 + Dim.3, data = pca_scores) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.122059 -0.014878 0.003712 0.023649 0.069936 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.1858849 0.0021959 84.650 &lt; 2e-16 *** ## Dim.1 0.0090654 0.0010548 8.595 1.18e-15 *** ## Dim.2 -0.0009716 0.0015976 -0.608 0.544 ## Dim.3 0.0105085 0.0017697 5.938 1.03e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.03395 on 235 degrees of freedom ## Multiple R-squared: 0.3179, Adjusted R-squared: 0.3091 ## F-statistic: 36.5 on 3 and 235 DF, p-value: &lt; 2.2e-16 COMPONENT 3 Explore correlations between the first 3 PCs and the response variable: ## [,1] ## Dim.1 -0.4976319 ## Dim.2 0.1300863 ## Dim.3 -0.2261493 Lets fit a linear model with the first few components as predictors: ## ## Call: ## lm(formula = relative_load_comp_3 ~ Dim.1 + Dim.2 + Dim.3, data = pca_scores) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.29076 -0.06453 -0.02615 0.04149 0.39697 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.216295 0.007363 29.375 &lt; 2e-16 *** ## Dim.1 -0.032615 0.003537 -9.222 &lt; 2e-16 *** ## Dim.2 0.012914 0.005357 2.411 0.0167 * ## Dim.3 -0.024869 0.005934 -4.191 3.94e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1138 on 235 degrees of freedom ## Multiple R-squared: 0.3157, Adjusted R-squared: 0.307 ## F-statistic: 36.14 on 3 and 235 DF, p-value: &lt; 2.2e-16 Not surprisingly, the coefficients are similar among humic components and while similar in absolute value, opposite for the protein-like component. Save this: Interpreting loadings for PC1: Negative Loadings Examples, clarifications: percent_Old.Forest as measured by a landcover classificaiton model (hand corrected Random Forest) percent_11.15 is the percent of the each subwatershed containing by forest btwn 11 and 15m tall as measured pixel counts of the canopy height model. These trees are ‘old’ but not the rare ancients found in the riparian valley. A negative loading in PC1 means that higher values of these variables are associated with lower values of the principal component (PC1), which ‘represents a particular combination of the variation explained by the dataset’ or in my words, a regression line that best fits the multidimensional space created by all of the variables. I think this means these are related to reduced Component1 fractions. Again, this is counter to Fegel results and the logic that the older forests would contain more recalcitrant sources of DOC. However, higher slopes and more tundra-covered areas also may negatively influence Component 1 humic fractions. This makes sense, as DOM is likely hydrologically transported faster in these conditions, with less time or material for microbial activity, transporting DOC while it is still labile. Positive Loadings: On the other hand, positive loadings mean that higher values of these variables contribute positively to PC1. Top examples, clarification: aspect higher aspect values (180 to 270) represent south and west aspects, 0-90 represent north and east. Previous studies that conclude that microbial decomposition of soil organic matter and enzyme activities associated with soil C, N, and P cycling increased with increasing temperature: Liu et al 2021 in Effects of natural vegetation restoration on DOM..and they cite: Min et al., 2019; Nazaries et al., 2015; Pang et al., 2015. disttostreams_mean is derived from a whitebox raster that calculates the downslope distance to the nearest downslope stream cell. This is assumed to give us a relative idea of the retention time of allochthonous water. Larger distances to the stream mean potentially more time for microbial activity to improve recalcitrance before DOM enters the stream channel. percent_cut.regenerating is the percent of subwatershed area covered by ‘cut’ plots. Thse are potentially areas of ‘newer’ forests, and in Deadhorse, many of these appear similar to meadows. We might expect a decreased humic component with regenerating forest as they can have lower litter production, shallow root systems, leading to decreased input of humic subtances (notes from a Tim meeting). However, we might be at an older stage of succession at this point (40+ years post harvest at this point). Roots are deeper, litter and deadwood has likely had time to accumulate in these plots. This can enhance complex, recalcitrant carbon compounds, like our humic Component1. percent_Beetle.kill Similar to above, beetle kill leaves the deadwood of old trees in place. We might expect these to be a source of recalcitrant carbon. TWI is arguably important in the fraction of humic components. Like distancetostreams, is likely an indication of the allochthonous water retention. In other words, increased water retention in areas with higher wetness indices, where DOM originating from surrounding soils (allochthonous DOM) can remain for extended periods may allow for greater microbial processing of DOM, leading to the accumulation of more recalcitrant, humic Components before the DOM is transported into the stream channel. "],["normalized-doc.html", "3.4 2. Normalized DOC", " 3.4 2. Normalized DOC As well as observing fractions of fluorescing DOC, we can normalize our total ‘loading’ or fluorescence by the DOC concentration. This could help us better examine lability of DOC and how much fluorescence signal is produced per unit of carbon and differences in overall DOM reactivity (i.e., does a larger proportion of DOM fluoresce in some samples relative to others). 3.4.1 Box plots - DOC normalized loadings Boxplots are visualizing DOC normalized loadings among watersheds Figure 3.27: Figure. Box plots showing the relationships the normalized fluorescence intensity and watershed. dh,dhn and dhs = Deadhorse, fc = Fool Creek. Horizontal bars indicate sample median, asterisks indicate sample mean. Whiskers (vertical lines) extend to the most extreme data point which is no more than range times the interquartile range from the box We can also explore normalized intensity, or the total fluorescence per unit of DOC of each PARAFAC component. Why do we care? Without normalization fluorescence intensity can be heaviliy influenced by DOC concentration. 3.4.1.1 Humic1 - or PARAFAC component 1 Figure 3.28: Figure. Box plots showing the relationships between the PARAFAC component 1 fluorescence intensity (humic-type) and watershed. dh,dhn and dhs = Deadhorse, fc = Fool Creek 3.4.1.2 Humic2 - or PARAFAC component 2 Figure 3.29: Figure. Box plots showing the relationships between the PARAFAC component 2 fluorescence intensity (humic-type) and watershed. dh,dhn and dhs = Deadhorse, fc = Fool Creek 3.4.1.3 Protein-like - or PARAFAC component 3 Figure 3.30: Figure. Box plots showing the relationships between the PARAFAC component 2 fluorescence intensity (humic-type) and watershed. dh,dhn and dhs = Deadhorse, fc = Fool Creek 3.4.2 Correlation matrices - Normalized loadings If matrices are in a purple gradient, then the plot includes all dates. If green, then the plot represents a subset of dates By looking at these, we are answering: “How does the actual concentration of a specific DOC component (humic, protein-like, etc.) change in relation to these watershed variables?” #### ALL EEMS ##### Landcover Figure 3.31: Figure. Combined plot showing the relationships between fluorescence intensity of 3 PARAFAC components and landcover characteristics for all samples with EEMs data (July 2021- Oct 1, 2022). Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. This figure indicates that: - The fluorescence intensity of humic DOM slightly decreases with high percentages of 6-10m canopy - The fluorescence intensity of humic DOM slightly increases with increasing watershed coverage of very tall canopy &gt;15m. Protein-like fluorescence intensity decreases with high percentages of cut or regenerating forest, and canopy between 6 and 10m, but increase with increased coverage by Tundra. Significant but weaker correlations indicate that protein-like fractions increase with increasing meadow and old forest coverage. Overall, these trends are similar to those seen when looking at fractions (rather than normalized intensities) but with lower correlations and less significance (greater variation) 3.4.2.0.1 Topo and moisture - all EEMS Figure 3.32: Figure. Combined plot showing the relationships between fluorescence intensity of 3 PARAFAC components and topographic or moisture characteristics for all samples with EEMs data (July 2021- Oct 1, 2022). Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. This figure indicates that: - the intensity of humic fluorescing DOM increases with increasing discharge. Humic fractions (DOC composition) show more relationships. Protein-like fluorescence intensity increases with increasing slope and distance from outlet. Protein-like fluorescence intensity decreases with increasing NDMI and TWI (moisture) and and increased mean distance to the stream channel. 3.4.2.0.2 Ions - all EEMS Figure 3.33: Figure. Combined plot showing the relationships between fluorescence intensity of 3 PARAFAC components and DOC (mg/L), and ions (mg/L) for all samples with EEMs data (July 2021- Oct 1, 2022). Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. This figure indicates that: - intensity of humic fluorescing DOM decreases with Potassium. - intensity of protein-like fluorescing DOM increase with increasing Ca+ and nitrate (NO3 - and the intensity of protein-like fluorescing DOM decreases withsodium, potassium (K) and fluoride (F) concentration)(same or similar resutls to fractions). 3.4.2.1 Summer subset 2022 (mid-June to mid July) 3.4.2.1.1 Landcover - summer 2022 Figure 3.34: Figure. Combined plot showing the relationships between fluorescence intensities of 3 PARAFAC components and landcover characteristics for EEMs samples collected between June 10 to July 15, 2022, which includes a synoptic sampling. Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. This figure indicates that humic fraction of the fluorescing DOM increase with high percentages of tundra, and short canopy. Protein-like fractions of the fluorescing DOM increase with high percentages of cut or regenerating forest, and canopy between 6 and 10m. Figure 3.35: Figure. Combined plot showing the relationships between relative loadings of 3 PARAFAC components and topographic or moisture characteristics for EEMs samples collected between June 10 to July 15, 2022, which includes a synoptic sampling. Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. This figure indicates that humic fraction of the fluorescing DOM increase with increasing discharge, the distance that allochthonous water travels before reaching the stream channel, and increased watershed moisture. Humic fractions decrease with watershed slope. Protein-like fractions of the fluorescing DOM increase with increasing slope and decrease with increasing Q, increasing moisture indices, and increased mean distance to the stream channel. 3.4.2.1.2 Ions - summer 2022 (mid-June to mid July) Figure 3.36: Figure. Combined plot showing the relationships between relative loadings of 3 PARAFAC components and DOC (mg/L), and ions (mg/L) EEMs samples collected between June 10 to July 15, 2022, which includes a synoptic sampling. Color indicates direction and correlation value (Pearson’s). Asterisks indicate level of significance. 3.4.3 Hydrograph - Fluorescence intensities in Fool creek with 2022 hydrograph Figure 3.37: Figure. Fluorescence intensities over time from Fool Creek outlet stream site only. Component 1 (humic) appears to increase with discharge while the fraction of Component 2 (humic) and Component 3 (protein-like) decrease during peak flow 3.4.4 PCA Figure 3.38: Figure. …BUT again, PCA is unsupervised and doesn’t directly consider the response variable. So how well does PC1 explain the variability of the first PARAFAC component (humic)?. Let’s look at PC1 in 2-D space by plotting it against our response variable to see how PC1 correlates with the sample fraction of Humic Component1. We can get a sense of the strength and direction of the relationship: Meh. Explore correlations between the first 3 PCs and the response variable: ## [,1] ## Dim.1 0.045068753 ## Dim.2 -0.006837438 ## Dim.3 0.150856896 Lets fit a linear model with the first few components as predictors: ## ## Call: ## lm(formula = norm_PARAF_c1 ~ Dim.1 + Dim.2 + Dim.3, data = pca_scores) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.413 -3.895 -1.514 1.741 29.896 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.07785 0.40042 20.174 &lt;2e-16 *** ## Dim.1 0.13456 0.19233 0.700 0.485 ## Dim.2 -0.03092 0.29131 -0.106 0.916 ## Dim.3 0.75571 0.32270 2.342 0.020 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.19 on 235 degrees of freedom ## Multiple R-squared: 0.02484, Adjusted R-squared: 0.01239 ## F-statistic: 1.995 on 3 and 235 DF, p-value: 0.1154 There is a significant and decent correlation with PC3: 3.4.5 RDA (Redundancy Analysis) -If explanatory variables must be centered, standardized, transformed or normalized We know from looking at distribuiton sin part 1 that our data is made up of quantitative variables with different units and numerical ranges. Standardization transforms the variables so they have a mean of zero and a standard deviation of one. Also, our response variables are right-skewed unimodal. We need to make the data more symmetrical or approximately normal, as RDA assumes linear relationships between variables. In the case of a right-skew, we can log transform to compress the long right tails and spread out lower values. Ok, now our responses are approximately normal. The scales are similar, the units are the same. I am not sure if we want to standardize/z-score these as well. This can ensure that they contribute equally to the analysis…lets try both and see if scaling makes a difference: scaled: ## Call: rda(formula = standardized_resp ~ aspect_mean + twi_mean + ndvi_raster_mean + ## disttostreams_mean + percent_Beetle.kill + percent_Old.Forest + percent_cut.regenerating + ## area_km + Qm3_s, data = explanatory_standardized, na.action = na.exclude) ## ## -- Model Summary -- ## ## Inertia Proportion Rank ## Total 3.0000 1.0000 ## Constrained 0.3314 0.1105 3 ## Unconstrained 2.6686 0.8895 3 ## ## Inertia is variance ## ## -- Eigenvalues -- ## ## Eigenvalues for constrained axes: ## RDA1 RDA2 RDA3 ## 0.21235 0.11724 0.00181 ## ## Eigenvalues for unconstrained axes: ## PC1 PC2 PC3 ## 2.3090 0.3302 0.0294 Constrained variance (0.009048, 48.1%): This is the portion of the total variance in the response matrix explained by the explanatory variables (e.g., area, slope, NDVI, etc.). i.e., variables explain around 48% of the variation the PARAFAC component fractions. Unconstrained variance (0.009779, 51.9%): This is not explained by the predictors, so more than half of the variation is not explained by the model. This returns the note Some constraints or conditions were aliased because they were redundant. This can happen if terms are linearly dependent (collinear): ‘percent_Tundra’. -Similar to PCA, but it is a constrained method that requries two datasets, one for response variables (e.g., PARAFAC component fractions) and one for explanatory variables (watershed characteristics) RDA identifies the portion of the variation in the response dataset that can be explained by the explanatory variables. So this tells us how much of the variability in the response variables is explained by the predictors. ## Call: rda(formula = response_matrix ~ aspect_mean + twi_mean + ndvi_raster_mean + ## disttostreams_mean + percent_Beetle.kill + percent_Old.Forest + percent_cut.regenerating + ## area_km + Qm3_s, data = explanatory_matrix, na.action = na.exclude) ## ## -- Model Summary -- ## ## Inertia Proportion Rank ## Total 54.31468 1.00000 ## Constrained 5.14670 0.09476 3 ## Unconstrained 49.16798 0.90524 3 ## ## Inertia is variance ## ## -- Eigenvalues -- ## ## Eigenvalues for constrained axes: ## RDA1 RDA2 RDA3 ## 3.271 1.868 0.008 ## ## Eigenvalues for unconstrained axes: ## PC1 PC2 PC3 ## 43.30 5.59 0.28 ## ## Call: ## rda(formula = response_matrix ~ aspect_mean + twi_mean + ndvi_raster_mean + disttostreams_mean + percent_Beetle.kill + percent_Old.Forest + percent_cut.regenerating + area_km + Qm3_s, data = explanatory_matrix, na.action = na.exclude) ## ## Partitioning of variance: ## Inertia Proportion ## Total 54.315 1.00000 ## Constrained 5.147 0.09476 ## Unconstrained 49.168 0.90524 ## ## Eigenvalues, and their contribution to the variance ## ## Importance of components: ## RDA1 RDA2 RDA3 PC1 PC2 PC3 ## Eigenvalue 3.27102 1.86771 0.0079711 43.3025 5.5903 0.275216 ## Proportion Explained 0.06022 0.03439 0.0001468 0.7973 0.1029 0.005067 ## Cumulative Proportion 0.06022 0.09461 0.0947571 0.8920 0.9949 1.000000 ## ## Accumulated constrained eigenvalues ## Importance of components: ## RDA1 RDA2 RDA3 ## Eigenvalue 3.2710 1.8677 0.007971 ## Proportion Explained 0.6356 0.3629 0.001549 ## Cumulative Proportion 0.6356 0.9985 1.000000 Take home: PCA and RDA do not work well with multicollinearity, yet many of our variables covary, not because they are redundant, rather they are likely driving each other in a path (i.e. topography influences landcover which influences hydrology which influences DOM) "],["biological-oxygen-demand-assays---data-exploration.html", "Chapter 4 Biological Oxygen Demand assays - data exploration", " Chapter 4 Biological Oxygen Demand assays - data exploration Objectives: 1. Format and summarize data from Biological Oxygen Demand (BOD) assays conducted on stream and well samples from the Fraser Experimental Forest. The samples were collected from 2021 to 2022, and the experiments were conducted in the summer of 2024. 2. Visualize the distributions and identify outliers in the BOD data. 3. Explore relationships between BOD data and Excitation-Emission Matrices (EEMs), as well as BOD and topographical/landcover characteristics of the subwatershed for each sample. stat_subset &lt;- rates_of_change %&gt;% filter(type == &#39;sample&#39;, watershed != &#39;SSFP&#39;) %&gt;% dplyr::select(-watershed) %&gt;% mutate(ID = as.integer(substr(as.character(sample_no), 1, 3))) Workflow: In the script, three datasets were imported: 1. the DO depletion at 10min intervals as recorded by PreSens instrument as experimental microcosms 2. the pre- and post-experiment DOC measurements for each sample as measured by the Shimadzu 3. EEMs results for the corresponding sample (if EEMs were collected for that sample) as well as topography, landcover data for the respective subwatershed. Formatting steps for the BOD data include: 1. DO depletion: - All tests/samples required an incubator adjustment period after the initiation of the test. [DO] would start low and climb as microcosms cooled and settled. Therefore, the peak DO between the 12th and 36th hour for each sample was used as the test ‘start’. - All 10min intervals were converted to a 2 hr rolling average to smooth short-term variation. -[DO] measurements were then transformed to a change in [DO] for each day by finding the slope of [DO]/time. 2. Change in DOC (Non-purgeable organic carbon or NPOC) - Experimental difference was determined by subtracting post-experimental reading from pre-experiment, and Figure 4.1: Figure. What is the relationship between measured change in sample DOC and daily DO loss? The relationship appears to be linear, but with a lot of variability. Let’s look at the distribution of each of these datasets and identify variability and outliers. We have two measurements from these experiments: the O2 within the microcosm measured at 10min intervals, and the change in DOC from the beginning of the experiment to the end. "],["daily-doc-loss-carbon.html", "4.1 Daily DOC loss (carbon)", " 4.1 Daily DOC loss (carbon) which represents the change in DOC standardized by the length of the experiment, calculated from the DOC measurement at the beginning of the experiment minus the DOC measurement after the experiment, divided by the number of days in the experiment. Let’s check the distribution and outliers of the change in DOC dataset. Visualize the distribution with a boxplot: ## [1] 0.1001613 It looks like we have 2 outliers that do note make sense (daily_DOC_loss), where the ‘loss’ is negative (&lt;0.1), implying that DOC increased post-experiment. Let’s remove those outliers and look at the distribution of DOC loss among watersheds. Figure 4.2: Figure. A boxplot of the measured DOC change in a sample/by # of experiment days across watersheds. "],["dissolved-oxygen-loss.html", "4.2 Dissolved oxygen loss", " 4.2 Dissolved oxygen loss Let’s check the distribution and outliers of the dissolved oxygen loss data. Visualize the distribution with a boxplot: No outliers here that I am concerned about, so lets look at distribution across watersheds: Figure 4.3: Figure. A boxplot of the measured daily rate of DO change across watersheds. This measurement seems to be much variable within watershed "],["explore-relationships..html", "4.3 Explore relationships.", " 4.3 Explore relationships. Filtered datasets can be played with here. If we filter dates to a single synoptic period so that we only have on one point for every landcover classification, the trends look very similar to that of the full dataset, where there is a weak but significant negative correlation between daily DOC change and areas with short canopy (percent_1.5). However, if we filter the entire dataset by sample position (i.e. streams vs wells) there is no correlation for any canopy class if looking at stream samples only. It appears that well samples are driving trends and significance in percent_1.5 and percent6.10. "],["demo-partial-least-squares-structural-equation-modeling-pls-sem.html", "Chapter 5 Demo: Partial least squares – Structural Equation Modeling (PLS-SEM)", " Chapter 5 Demo: Partial least squares – Structural Equation Modeling (PLS-SEM) ‘PLS-SEM is capable of estimating very complex models. For example, if theoretical or conceptual assumptions support large models and sufficient data are available (i.e., meeting minimum sample size requirements), PLS-SEM can handle models of almost any size, including those with dozens of constructs and hundreds of indicator variables. As noted by Wold (1985), PLS-SEM is virtually without competition when path models with latent variables are complex in their structural relationships.’ – From Hair et al. 2021, An Introduction to SEM, pg 21 Most of this material is in summary of ‘An Introduction to Structural Equation Modeling’ by Hair et al. 2021 and from PLS Path Modeling with R. by Sanchez, G. 2013 SEMinR cran documentation at https://cran.r-project.org/web/packages/seminr/vignettes/SEMinR.html#reporting-results-of-a-bootstrapped-pls Case studies with similar analyses: Gao, X., Qiu, L., Huang, X., Wu, M., &amp; Cao, X. (2024). Monitoring grey water footprint and associated environmental controls in agricultural watershed. Environ Sci Pollut Res Int, 31(7), 11334-11348. https://www.ncbi.nlm.nih.gov/pubmed/38217819 Kumar Gorai, A., Tuluri, F., &amp; Tchounwou, P. B. (2015). Development of PLS–path model for understanding the role of precursors on ground level ozone concentration in Gulfport, Mississippi, USA. Atmospheric Pollution Research, 6(3), 389-397. 5.0.0.1 Why PLS-SEM? Works efficiently with (relatively) small sample sizes and complex models (more on this later). Does not assume normal distribution of data Works with formative and reflective models – but does not include circular relationships or loops "],["building-the-path-model.html", "5.1 Building the path model", " 5.1 Building the path model We will work first with an initial model so I can define terminology. We will cover structural theory after covering vocabulary 5.1.1 Path diagram of our model with tested indicators NOTE You may disagree with the arrangement of some of these indicators as they relate to the latent variables. That is as intended. We want to use this model to test the validity measures and demonstrate how they can guide a more logical path model. Latent variables are indirectly measured by means of variables which can be perfectly observed-measured. These types of variables are called manifest variables (MVs), also known as indicators. We use the information contained in indicators to obtain an approximate representation of the latent variable. Inner Model – Captures the relationships between latent variables (e.g., topography → landcover → runoff → DOC composition). The Outer Model Represents how the manifest variables/indicators load onto their corresponding latent variables. Here, we need to consider whether the lack of strong correlations within indicator sets on the “cause” side could limit the model’s explanatory power in capturing the full variance of latent variables like topography. There are checks to measure this. We will explore these after we run the model. Exogeneous latent variables only explain other constructs in the model. (e.g. Topography) Indicators of these be called formative Endogeneous latent variables are being explained in the model(Hydrological, landcover and DOM), according to Fig.1.1 in Hair et al. 2021, Indicators of these may be called reflexive variables Measurement theory specifies how the latent variables are measured. Since these are unobservable variables, we can measure them with ‘reflective ’measurements (i.e., direction of the arrows is from the indicator to the latent variable) or ‘formative’ measurements (arrow is from the latent variable to the measurement, indicating that the latent variable ‘causes’ the measurement). Structural theory shows how the latent variables are related to one another. When the path model is developed, the sequence is from left to right, Variables on the left side of the path are independent variables, and variables on the right side are dependent. Moreover, variables on the left are show a sequentially preceding and predicting the variables on the right. When variables are in the middle of the model, the serve as both independent and dependent variables in the structural model. Error terms are connected to the endogenous constructs and (reflectively) measured indicators. Error terms represent the unexplained variance when path models are estimated. i.e. the difference between the model’s in-sample prediction of a value and an observed value of an indicator or latent variable. In contrast, the formatively measured indicators (like those of topography) do not have error terms. And for DOM lability, the direction of the relationships between the latent variable and indicator are not relevant, as they are assumed to be equivalent. So, there is no error term associated with those indicators. Now that we have a path model, we need to test the theoretical relationships within that model. "],["data-managment-transformation.html", "5.2 Data managment / transformation", " 5.2 Data managment / transformation For this model demonstration, our EEMs dataset has been filtered to ‘stream’ samples only (no wells) (n= 91). Our full sample, including wells, and a filtered sample evaluating only wells returns reduced DOM r^2 values (between 0.15 and .3) relative to streams alone, which tend to yield better results. The selection process for these variables includes review of the specific response variable, and the correlations of that variable with the explanatory variables found in combine_PARAFAC_w_ws, part 1.B.ii. 1. More on size: - A.10x rule: sample size should be – to 10x the number if independent variables (number of arrows pointing to a a latent variable) (Barclay, Higgins &amp; Thompson, 1995) - May still be too small, depending on complexity of model. - B. inverse square root method (a retrospective approach) -We take the path coefficient (a number showing the strength of the relationship between two variables) and divide it by its standard error (a measure of how much this coefficient might vary if the analysis is repeated). -Compare this ratio to a critical value that depends on the significance level we’re using (e.g., 1.96 for a 5% significance level in a two-tailed test). If the ratio is greater than the critical value, it suggests the relationship (path coefficient) is statistically significant. Hair 2021 pg 17 has equations for the desired significance level, e.g., \\[ \\text{Significance level} = 5\\%: \\quad n_{\\text{min}} &gt; \\left( \\frac{2.486}{p_{\\text{min}}} \\right)^2 \\] Where pmin is the value of the path coefficient with the minimum magnitude in the PLS path model. We can find that after we run the model with pls_model$path_coefs 2. Measurement scales measurements should be on a metric scale, ratio or interval scale. Could also be ordinal scales if datapoints are equidistant, or with binary data. Categorical data can be binary-coded, but may need additional attention when making interpretations. See Hair et al. 2022 PLS-SEM Primer if it comes to this 3. Missing data: All missing values need to be treated or removed. if less than 5% of values are missing per indicator, mean replacement or nearest neighbor will likely be used, depending on the nature of the missing data. We don’t have many of these. 4. Treatment of FEF data These are all quantitative variables with different units and numerical ranges. We first log-transformed discharge adding 1e-9 as a constant Transformations are common when dealing with variables that have non-normal distributions or large ranges in ecology. Justifying transformations based on the ecological characteristics of the data (e.g., discharge typically has an exponential distribution in headwater streams) enhances the credibility of the model. Using transformations helps to uncover meaningful ecological patterns that might be masked if extreme or skewed data overpowered the model. In practice, documenting and justifying each transformation based on ecological knowledge of the variables strengthens the model’s interpretability and credibility. This approach allows transformations to enhance the alignment between model structure and real-world processes. After transforming discharge, we standardized all columns in the dataframe. Standardization transforms the variables so they have a mean of zero and a standard deviation of one. Let’s view the scaled distributions of standardized explanatory variables: Figure 5.1: Figure. Checking out the distribution of explanatory variables Build the outer model or ‘constructs’ or latent variables simple_FEF_mm &lt;- constructs( composite(&quot;TOPO&quot;, multi_items(&quot;topo_&quot;, 1:4)), composite(&quot;HYDRO&quot;, single_item(&quot;hydro_1&quot;)), composite(&quot;LANDCOVER&quot;, multi_items(&quot;landcover_&quot;, 1:2)), composite(&quot;DOC&quot;, single_item(&#39;doc_1&#39;)) ) Now for the structural model: # Create structural model simple_FEF_sm &lt;- relationships( paths(from = c(&quot;TOPO&quot;), to = c(&quot;HYDRO&quot;, &quot;LANDCOVER&quot;, &quot;DOC&quot;)), paths(from = c(&quot;LANDCOVER&quot;), to = c(&quot;HYDRO&quot;, &quot;DOC&quot;)), paths(from = c(&quot;HYDRO&quot;), to = c(&quot;DOC&quot;))) # Note that neither a dataset nor a measurement model is specified in the structural model stage, so we can reuse the structural model object simple_sm across different datasets and measurement models. Model Estimation using the PLS-SEM algorithm. The algorithm needs to determine the scores of the constructs that are used as input for partial regression models within the path model. After the algorithm has calculated the construct scores, the scores are used to estimate each partial regression model in the path model. As a result, we obtain the estimates for all relationships in the measurement models (i.e., the indicator weights/loadings) and the structural model (i.e., the path coefficients). (more on pg 60 of Hair) summarize output "],["reporting-initial-results-and-evaluating-the-quality-of-reflective-measurement-models.html", "5.3 Reporting initial results and evaluating the quality of reflective measurement models", " 5.3 Reporting initial results and evaluating the quality of reflective measurement models estimated by PLS-SEM both in terms of reliability and validity. A plot of result reliability measures: plot(summary_simple_fef$reliability) Indicator reliability: First we want to know how much of each indicator’s variance is explained by the latent variable it is assigned to. ‘To compute an indicator’s explained variance, we need to square the indicator loading, which is the bivariate correlation between indicator and construct. As such, the indicator reliability indicates the communality of an indicator. Indicator loadings above 0.708 are recommended, since they indicate that the construct explains more than 50 percent of the indicator’s variance, thus providing acceptable indicator reliability.’ Hair et al. 2021 ## TOPO LANDCOVER HYDRO DOC ## topo_1 0.665 0.000 0.000 0.000 ## topo_2 0.755 0.000 0.000 0.000 ## topo_3 0.279 0.000 0.000 0.000 ## topo_4 0.846 0.000 0.000 0.000 ## hydro_1 0.000 0.000 1.000 0.000 ## landcover_1 0.000 0.807 0.000 0.000 ## landcover_2 0.000 0.783 0.000 0.000 ## doc_1 0.000 0.000 0.000 1.000 Take home: Our current topo_3 (subwatershed area in m^2) as a low reliability which can contribute to more measurement error to the model, which can weaken the model’s validity and interpretability. This means that less than 50% of it’s variance is explained by other ‘topography’ indicators, which makes sense. topo_3 represents watershed area may be a better variable to group with ‘hydrology’ rather than topograhy. We’ll test this along with other model variations in the next chapter. Then we want to check the ‘internal consistency reliability’ (rhoC). Internal consistency reliability is the extent to which indicators measuring the same construct are associated with each other. ’Higher values indicate higher levels of reliability. For example, reliability values between 0.60 and 0.70 are considered “acceptable in exploratory research,” whereas values between 0.70 and 0.90 range from “satisfactory to good.” Values above 0.90 (and definitely above 0.95) are problematic, since they indicate that the indicators are redundant, thereby reducing construct validity (Diamantopoulos, Sarstedt, Fuchs, Wilczynski, &amp; Kaiser, 2012).’Hair et al. 2021 Other sources indicate that 0.85 is a more conservative threshold value. ## alpha rhoC AVE rhoA ## TOPO 0.792 0.871 0.636 0.836 ## LANDCOVER 0.742 0.886 0.795 0.744 ## HYDRO 1.000 1.000 1.000 1.000 ## DOC 1.000 1.000 1.000 1.000 ## ## Alpha, rhoC, and rhoA should exceed 0.7 while AVE should exceed 0.5 Our rhoC values fall in the higher (not ideal) range of ‘satisfactory to good’ but our ‘problematic’ values are due to these latent values having single indicators, so they aren’t truly problematic. Convergent Validity: When we assess convergent validity, we’re checking how well each indicator represents the latent variable it’s supposed to measure. For convergent validity, we want to see if the indicators of the same latent variable are closely related rather than explaining different processes. This is where average variance extracted (AVE) comes in: AVE shows how much of the total variance in the indicators is actually explained by the construct. ## alpha rhoC AVE rhoA ## TOPO 0.792 0.871 0.636 0.836 ## LANDCOVER 0.742 0.886 0.795 0.744 ## HYDRO 1.000 1.000 1.000 1.000 ## DOC 1.000 1.000 1.000 1.000 ## ## Alpha, rhoC, and rhoA should exceed 0.7 while AVE should exceed 0.5 Here then we should not be surprised to see 1.00 for HYDRO and DOC AVE, as, up to this point, we have included only one indicator for these latent variables. However, for topo and landcover, we can be confident that we have chosen variables that are measuring the same thing as our AVE are high (over 0.5) Discriminant Validity Now we want to make sure that different latent variables in the model are distinct from each other, ie. they measure different concepts. One way to check this is by using the heterotrait–monotrait (HTMT) ratio. If the HTMT values are low (typically below 0.9), it indicates that the constructs are distinct and measure different concepts. ## TOPO LANDCOVER HYDRO DOC ## TOPO . . . . ## LANDCOVER 1.053 . . . ## HYDRO 0.486 0.501 . . ## DOC 0.584 0.554 0.305 . In this current configuration, topo and landcover may not be distinct. This is hardly surprising, landcover indicators are often directly and strongly correlated with many of the topographical variables. In this case, we are looking at the percentage of each subwatershed that is covered by ‘cut/regenerating’ forest. Many of these sites were on lower slopes (likely for ease of access), and in the case of Deadhorse, almost entirely on the southern aspect. Furthermore, ‘TWI’ or the total wetness index likely drives NDVI. A high correlation between topography and landcover in our SEM model isn’t necessarily problematic if it aligns with the underlying ecology of the study area Combining them into a single latent variable isn’t ideal for our research question, where we want to see if we can evaluate the impacts of land cover independent of topography. We may not have this issue if we look at other land cover types. Let’s come back to this to see if it needs addressing. We might be able to control for one construct in relation to the other, such as controlling for topography when examining landcover’s effect, to clarify their roles without removing one or the other. "],["bootstrapping-for-significance.html", "5.4 Bootstrapping for significance", " 5.4 Bootstrapping for significance PLS-SEM is a nonparametric method – thus, we need to perform bootstrapping to estimate standard errors and compute confidence intervals. Here we’ll use the bootstrap_model() function and specify the arguments seminr_model = corp_rep_simple_model, nboot = 1000, cores = NULL, seed = 123. In other words, we use 1,000 bootstrap subsamples. However, the final result computations should draw on 10,000 subsamples (Streukens &amp; Leroi-Werelds, 2016). These computations will take a while so we will do them after exploring other model configurations. 5.4.1 Reporting results of bootstrapped PLS ## Original Est. Bootstrap Mean Bootstrap SD T Stat. 5% CI 95% CI ## TOPO -&gt; LANDCOVER 1.053 1.051 0.123 8.566 0.823 1.217 ## TOPO -&gt; HYDRO 0.486 0.483 0.069 7.007 0.369 0.591 ## TOPO -&gt; DOC 0.584 0.581 0.082 7.126 0.429 0.702 ## LANDCOVER -&gt; HYDRO 0.501 0.496 0.121 4.136 0.280 0.682 ## LANDCOVER -&gt; DOC 0.554 0.551 0.112 4.966 0.349 0.721 ## HYDRO -&gt; DOC 0.305 0.302 0.112 2.715 0.112 0.487 This gives us the confidence intervals of the HTMT ratio. Again, our bootstrapped HTMT ratio indicating the high correlation between topography and landcover. The bootstrapping procedure yields t-values for the indicator weights (and other model parameters). We need to compare these t-values with the critical values from the standard normal distribution to decide whether the coefficients are significantly different from zero. Assuming a significance level of 5%, a t-value above 1.96 (two-tailed test) suggests that the indicator weight is statistically significant. Interpretation: As an example between Landcover and DOC B = -0.068: This is the standardized path coefficient between the two latent variables. A negative value (-0.068) indicates a weak negative relationship, meaning that as one variable increases slightly, the other decreases slightly, though the effect is minimal here. 95% CI [-0.332, 0.261]: This is the 95% confidence interval for the beta value, giving a range within which the true beta value is likely to fall, with 95% confidence. Since this interval includes zero (spanning from -0.332 to 0.261), the effect of landcover on DOC here could be statistically insignificant. So, in this current configuration, the standardized path coefficients between TOPO and LANDCOVER are significant and TOPO and DOC are significant (as our TOPO indicator variables increase, the fragment of DOC that is protein-like increases), but as the model is organized now, the effect of Landcover and hydrology are minimal and not significant. "],["pls_sem-automation.html", "Chapter 6 PLS_SEM Automation ", " Chapter 6 PLS_SEM Automation "],["workflow-description.html", "6.1 Workflow description:", " 6.1 Workflow description: Here we are using a form of Monte Carlo-based Partial Least Squares - SEM with model screening and post-hoc variable significance analysis. The workflow is as follows: Model automation with random indicator selection We run 20,000 iteration of PLS-SEM models (which predict a response variable related to DOC characteristics) where a subset of indicators is randomly selected for each model In this script, we have run 20000 iterations for 6 different subsets of data: Model 1: one for all flows (n=91) with ‘humic’ responses (complex, high weight, stable, partially degradable by microbes) AND IONS as indicator variables. Here we demonstrate that while ions can improve response R^2 values, they may not contribute to path model in a meaningful way. Model 2: high flows (n=33) with ‘humic’ responses - NO IONS Model 3: high flows (n=33) with ‘labile’ responses (simpler, lower weight, high bioavailabilty, easily decomposed) Model 4: low flows (n=64) with ‘humic’ responses Model 5: low flows (n=64) with ‘labile’ responses Each iteration screens and retains results based on two criteria: High reliability metrics High R2 for the response variable. This is easily changed in the automation function, currently set at 0.4. Analysis of indicator frequency: Among saved models (~1% of all iterations), we analyze the frequency of indicators across retained models we also review the relationship between indicator frequency and the response r2 this might need a little more work to formalize this process. We could come up with an equation, maybe of all models run where this indicator shows up, what percent have an R2 &lt; than 0.1, 0.2…etc? Some initial observations Indicators that appear in models with the highest R2 values often have low overall frequency across a broader set of retained models. Specific to this tend to be indicators of water ion concentrations. While these indicators may occasionally yield strong predictive power (high R2), their overall contribution to the DOC characteristic process may be unlikely or spurious. This workflow is intended to identify high-performing models with strong explanatory power (high R²). However, indicators that appear exclusively in a few high-R² models but have low frequency across other retained models may not reflect robust drivers of the DOC processes. Instead, their significance may result from chance, suggesting these indicators have low probability of being substantively important despite their occasional high R² contribution. Therefore, in the final model selection, we will build models with higher probability as determined by some measure of frequency and mean r2. Indicator Frequency-Predictive Value Analysis (IF-PVA)? Check PLS_SEM literature and see if they have something similar. "],["the-code.html", "6.2 The code:", " 6.2 The code: For this model demonstration, our EEMs dataset has been filtered to ‘stream’ samples only (no wells) (n= 91) 6.2.1 Model 1: High flows - HUMIC -W/NUTRIENTS (AUTOMATED) 6.2.1.1 Indicator list These will be the indicators that will be randomly selected from during automation. Select labile or humic DOC responses here model_df &lt;- data.frame(matrix(ncol = 0, nrow = nrow(filtered_df))) indicators &lt;- list( topo = c( &quot;disttostreams_mean&quot;, &quot;aspect_mean_rad&quot;, &#39;twi_mean&#39;, &#39;area_km&#39;, &quot;elevabovestreams_mean&quot;), hydro = c(&quot;snowpack_3day_avg&quot;, &quot;discharge_m2&quot;), landcover = c(&quot;percent_Beetle.kill&quot;, &quot;percent_Meadows&quot;,&quot;percent_Old.Forest&quot;,&quot;percent_cut.regenerating&quot;, &quot;percent_Tundra&quot; ,&quot;ndvi_raster_mean&quot;), doc = c(&quot;relative_load_comp_1&quot;, &quot;relative_load_comp_2&quot;, &quot;norm_PARAF_c1&quot;, &quot;norm_PARAF_c2&quot;, &quot;peak_T_275.340&quot;, &quot;Fluorescence_Index&quot;, &quot;SUVA254&quot;, &quot;peak_ratioAT&quot;, &quot;peak_ratioCT&quot;), nutr = c(&#39;NO3_mg.l&#39;, &quot;na_mg.l&quot;, &quot;nh4_mg.l&quot;, &quot;K_mg.l&quot;, &quot;Mg_mg.l&quot;, &quot;Ca_mg.l&quot;, &quot;F_mg.l&quot;, &quot;Cl_mg.l&quot;, &quot;SO4_mg.l&quot;) ) 6.2.1.2 Run the function written in .R script Here we have the option of running multiple iterations, or if this has already been done, we can import the .rds generated from 20000 runs. ## [1] &quot;20000 run winner: &quot; ## [1] 0.5443818 ## $topo ## [1] &quot;elevabovestreams_mean&quot; ## ## $hydro ## [1] &quot;snowpack_3day_avg&quot; ## ## $landcover ## [1] &quot;percent_Tundra&quot; ## ## $doc ## [1] &quot;peak_ratioCT&quot; &quot;SUVA254&quot; &quot;relative_load_comp_1&quot; ## ## $nutr ## [1] &quot;Mg_mg.l&quot; Or we can find the highest performing model where some value is specified for the ‘DOC’ response. ## Best R^2 for DOC: 0.5443818 ## Selected DOC response: ## [1] &quot;relative_load_comp_1&quot; ## Sampled indicators for best model: ## $topo ## [1] &quot;elevabovestreams_mean&quot; ## ## $hydro ## [1] &quot;snowpack_3day_avg&quot; ## ## $landcover ## [1] &quot;percent_Tundra&quot; ## ## $doc ## [1] &quot;peak_ratioCT&quot; &quot;SUVA254&quot; &quot;relative_load_comp_1&quot; ## ## $nutr ## [1] &quot;Mg_mg.l&quot; 6.2.1.3 Visualizing all selected results (r2 of DOC &gt;0.4) 6.2.1.3.1 Indicator frequency 6.2.1.3.2 R2 distribution 6.2.1.3.3 Combine these two ideas: Create the dataframe 6.2.1.4 Visualizing specific DOC results (r2 of DOC &gt;0.4) 6.2.1.4.1 Indicator frequency 6.2.1.4.2 Combine these two ideas: Create the dataframe 6.2.1.5 Generate flow diagram for the top performing model ## [1] &quot;topo_1&quot; &quot;hydro_1&quot; &quot;landcover_1&quot; &quot;doc_1&quot; &quot;doc_2&quot; &quot;doc_3&quot; &quot;nutr_1&quot; ## Generating the seminr model ## All 91 observations are valid. ## ## Results from package seminr (2.3.4) ## ## Path Coefficients: ## HYDRO LANDCOVER NUTRIENT DOC ## R^2 0.026 0.393 0.059 0.558 ## AdjR^2 0.004 0.386 0.038 0.537 ## TOPO -0.087 0.627 -0.121 -0.150 ## LANDCOVER -0.091 . -0.148 -0.634 ## HYDRO . . . 0.084 ## NUTRIENT . . . -0.397 ## ## Reliability: ## alpha rhoC AVE rhoA ## TOPO 1.000 1.000 1.000 1.000 ## LANDCOVER 1.000 1.000 1.000 1.000 ## HYDRO 1.000 1.000 1.000 1.000 ## NUTRIENT 1.000 1.000 1.000 1.000 ## DOC 0.778 0.874 0.702 0.832 ## ## Alpha, rhoC, and rhoA should exceed 0.7 while AVE should exceed 0.5 ## Original Est. Bootstrap Mean Bootstrap SD T Stat. 5% CI 95% CI ## TOPO -&gt; LANDCOVER 0.627 0.614 0.097 6.451 0.432 0.755 ## TOPO -&gt; HYDRO 0.144 0.148 0.074 1.958 0.028 0.273 ## TOPO -&gt; NUTRIENT 0.214 0.224 0.116 1.838 0.039 0.421 ## TOPO -&gt; DOC 0.524 0.512 0.118 4.430 0.307 0.691 ## LANDCOVER -&gt; HYDRO 0.146 0.143 0.048 3.057 0.063 0.220 ## LANDCOVER -&gt; NUTRIENT 0.224 0.220 0.086 2.610 0.082 0.364 ## LANDCOVER -&gt; DOC 0.734 0.723 0.102 7.190 0.539 0.866 ## HYDRO -&gt; NUTRIENT 0.472 0.474 0.071 6.641 0.353 0.583 ## HYDRO -&gt; DOC 0.049 0.102 0.050 0.976 0.034 0.196 ## NUTRIENT -&gt; DOC 0.203 0.219 0.113 1.801 0.055 0.412 This gives us the confidence intervals of the HTMT ratio. print(indicators) ## $topo ## [1] &quot;elevabovestreams_mean&quot; ## ## $hydro ## [1] &quot;snowpack_3day_avg&quot; ## ## $landcover ## [1] &quot;percent_Tundra&quot; ## ## $doc ## [1] &quot;peak_ratioCT&quot; &quot;relative_load_comp_1&quot; &quot;SUVA254&quot; ## ## $nutr ## [1] &quot;Mg_mg.l&quot; 6.2.2 Model 2: High flows - HUMIC -WO/NUTRIENTS (AUTOMATED) 6.2.2.1 Indicator list These will be the indicators that will be randomly selected from during automation. Select labile or humic DOC responses here model_df &lt;- data.frame(matrix(ncol = 0, nrow = nrow(filtered_df))) indicators &lt;- list( topo = c( &quot;disttostreams_mean&quot;, &#39;twi_mean&#39;, &#39;area_km&#39;, &quot;elevabovestreams_mean&quot;, &quot;aspect_mean_rad&quot;), hydro = c(&quot;snowpack_3day_avg&quot;, &quot;discharge_m2&quot;), landcover = c(&quot;percent_Beetle.kill&quot;, &quot;percent_Meadows&quot;,&quot;percent_Old.Forest&quot;,&quot;percent_cut.regenerating&quot;, &quot;percent_Tundra&quot; ,&quot;ndvi_raster_mean&quot;), doc = c(&quot;relative_load_comp_1&quot;, &quot;relative_load_comp_2&quot;, &quot;norm_PARAF_c1&quot;, &quot;norm_PARAF_c2&quot;, &quot;peak_T_275.340&quot;, &quot;Fluorescence_Index&quot;, &quot;SUVA254&quot;, &quot;peak_ratioAT&quot;, &quot;peak_ratioCT&quot;) ) 6.2.2.2 Run the function written in .R script ## [1] &quot;20000 run winner: &quot; ## [1] 0.8524449 ## $topo ## [1] &quot;twi_mean&quot; ## ## $hydro ## [1] &quot;discharge_m2&quot; ## ## $landcover ## [1] &quot;percent_Tundra&quot; ## ## $doc ## [1] &quot;Fluorescence_Index&quot; Or we can find the highest performing model where some value is specified for the ‘DOC’ response ## Best R^2 for DOC: 0.6440625 ## Selected DOC response: ## [1] &quot;relative_load_comp_2&quot; ## Sampled indicators for best model: ## $topo ## [1] &quot;twi_mean&quot; ## ## $hydro ## [1] &quot;snowpack_3day_avg&quot; ## ## $landcover ## [1] &quot;percent_cut.regenerating&quot; &quot;percent_Tundra&quot; ## ## $doc ## [1] &quot;relative_load_comp_1&quot; &quot;SUVA254&quot; &quot;relative_load_comp_2&quot; 6.2.2.3 Visualizing all selected results (r2 of DOC &gt;0.4) 6.2.2.3.1 Indicator frequency 6.2.2.3.2 R2 distribution 6.2.2.3.3 Combine these two ideas: Create the dataframe 6.2.2.4 Visualizing specific DOC results (r2 of DOC &gt;0.4) 6.2.2.4.1 Indicator frequency 6.2.2.4.2 R2 distribution 6.2.2.4.3 Combine these two ideas: Create the dataframe 6.2.2.5 Generate flow diagram for the top performing model ## [1] &quot;topo_1&quot; &quot;hydro_1&quot; &quot;landcover_1&quot; &quot;landcover_2&quot; &quot;doc_1&quot; &quot;doc_2&quot; &quot;doc_3&quot; ## Generating the seminr model ## All 33 observations are valid. ## ## Results from package seminr (2.3.4) ## ## Path Coefficients: ## HYDRO LANDCOVER DOC ## R^2 0.070 0.709 0.644 ## AdjR^2 0.008 0.699 0.607 ## TOPO -0.337 0.842 0.865 ## LANDCOVER 0.476 . -0.089 ## HYDRO . . 0.102 ## ## Reliability: ## alpha rhoC AVE rhoA ## TOPO 1.000 1.000 1.000 1.000 ## LANDCOVER 1.000 1.000 1.000 1.000 ## HYDRO 1.000 1.000 1.000 1.000 ## DOC 0.829 0.897 0.745 0.843 ## ## Alpha, rhoC, and rhoA should exceed 0.7 while AVE should exceed 0.5 ## Original Est. Bootstrap Mean Bootstrap SD T Stat. 5% CI 95% CI ## TOPO -&gt; LANDCOVER 0.842 0.850 0.054 15.691 0.761 0.940 ## TOPO -&gt; HYDRO 0.064 0.141 0.101 0.635 0.015 0.334 ## TOPO -&gt; DOC 0.866 0.861 0.071 12.208 0.737 0.971 ## LANDCOVER -&gt; HYDRO 0.193 0.200 0.116 1.667 0.022 0.400 ## LANDCOVER -&gt; DOC 0.724 0.729 0.081 8.939 0.601 0.849 ## HYDRO -&gt; DOC 0.163 0.220 0.086 1.892 0.105 0.369 This gives us the confidence intervals of the HTMT ratio. print(indicators) ## $topo ## [1] &quot;twi_mean&quot; ## ## $hydro ## [1] &quot;snowpack_3day_avg&quot; ## ## $landcover ## [1] &quot;percent_cut.regenerating&quot; &quot;percent_Tundra&quot; ## ## $doc ## [1] &quot;relative_load_comp_1&quot; &quot;SUVA254&quot; &quot;relative_load_comp_2&quot; 6.2.3 Model 3: High flows - LABILE -WO/NUTRIENTS (AUTOMATED) 6.2.3.1 Indicator list These will be the indicators that will be randomly selected from during automation. Select labile or humic DOC responses here model_df &lt;- data.frame(matrix(ncol = 0, nrow = nrow(filtered_df))) indicators &lt;- list( topo = c( &quot;disttostreams_mean&quot;, &#39;twi_mean&#39;, &#39;area_km&#39;, &quot;elevabovestreams_mean&quot;, &quot;aspect_mean_rad&quot;), hydro = c(&quot;snowpack_3day_avg&quot;, &quot;discharge_m2&quot;), landcover = c(&quot;percent_Beetle.kill&quot;, &quot;percent_Meadows&quot;,&quot;percent_Old.Forest&quot;,&quot;percent_cut.regenerating&quot;, &quot;percent_Tundra&quot; ,&quot;ndvi_raster_mean&quot;), doc = c(&quot;relative_load_comp_3&quot;, &quot;norm_PARAF_c3&quot;, &quot;peak_T_275.340&quot;, &quot;Fluorescence_Index&quot;, &quot;SUVA254&quot;, &quot;peak_ratioAT&quot;, &quot;peak_ratioCT&quot;) ) 6.2.3.2 Run the function written in .R script ## [1] &quot;20000 run winner: &quot; ## [1] 0.855127 ## $topo ## [1] &quot;aspect_mean_rad&quot; ## ## $hydro ## [1] &quot;discharge_m2&quot; ## ## $landcover ## [1] &quot;percent_Tundra&quot; &quot;percent_cut.regenerating&quot; &quot;percent_Meadows&quot; ## ## $doc ## [1] &quot;Fluorescence_Index&quot; Or we can find the highest performing model where some value is specified for the ‘DOC’ response ## Best R^2 for DOC: 0.7697365 ## Selected DOC response: ## [1] &quot;relative_load_comp_3&quot; ## Sampled indicators for best model: ## $topo ## [1] &quot;twi_mean&quot; ## ## $hydro ## [1] &quot;discharge_m2&quot; ## ## $landcover ## [1] &quot;percent_Tundra&quot; &quot;ndvi_raster_mean&quot; &quot;percent_cut.regenerating&quot; ## ## $doc ## [1] &quot;relative_load_comp_3&quot; &quot;norm_PARAF_c3&quot; &quot;Fluorescence_Index&quot; 6.2.3.3 Visualizing all selected results (r2 of DOC &gt;0.4) 6.2.3.3.1 Indicator frequency 6.2.3.3.2 R2 distribution 6.2.3.3.3 Combine these two ideas: Create the dataframe 6.2.3.4 Visualizing specific DOC results (r2 of DOC &gt;0.4) 6.2.3.4.1 Indicator frequency 6.2.3.4.2 R2 distribution 6.2.3.4.3 Combine these two ideas: Create the dataframe Select the ‘best’ indicators based on mean R2, standard deviation and probability of appearance. # Calculate percentage for each indicator and category result &lt;- indicator_list %&gt;% group_by(Indicator, Category) %&gt;% summarise(count = n(), .groups = &quot;drop&quot;) %&gt;% mutate(percentage = count / max(indicator_list$Iteration) * 100) # Add a ranking index based on mean_R2 and sd_R2 where I want the highest ranking for indicators with relatively mean R^2 and relatively small standard deviation. result &lt;- indicator_list %&gt;% group_by(Indicator, Category) %&gt;% summarise( count = n(), mean_R2 = mean(R2, na.rm = TRUE), sd_R2 = sd(R2, na.rm = TRUE), .groups = &quot;drop&quot; ) %&gt;% mutate( percentage = count / max(indicator_list$Iteration) * 100, # Normalize mean_R2 (higher is better) and sd_R2 (lower is better) mean_R2_norm = (mean_R2 - min(mean_R2)) / (max(mean_R2) - min(mean_R2)), sd_R2_norm = (max(sd_R2) - sd_R2) / (max(sd_R2) - min(sd_R2)), # Create a custom index (e.g., weighted sum of normalized values) ranking_index = mean_R2_norm * 0.7 + sd_R2_norm * 0.3 ) %&gt;% arrange(desc(ranking_index)) # Sort by the ranking index in descending order # View the result print(result) ## # A tibble: 17 × 9 ## Indicator Category count mean_R2 sd_R2 percentage mean_R2_norm sd_R2_norm ranking_index ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 twi_mean topo 44 0.611 0.0691 40.7 1 0.927 0.978 ## 2 percent_Beetle.kill landcov… 37 0.535 0.0648 34.3 0.409 0.993 0.584 ## 3 percent_Old.Forest landcov… 24 0.553 0.0898 22.2 0.547 0.618 0.569 ## 4 percent_Tundra landcov… 28 0.570 0.116 25.9 0.680 0.219 0.542 ## 5 norm_PARAF_c3 doc 44 0.547 0.0989 40.7 0.507 0.482 0.500 ## 6 peak_ratioAT doc 35 0.541 0.0910 32.4 0.455 0.601 0.499 ## 7 snowpack_3day_avg hydro 56 0.538 0.0902 51.9 0.436 0.612 0.488 ## 8 percent_cut.regener… landcov… 108 0.538 0.0964 100 0.433 0.519 0.459 ## 9 relative_load_comp_3 doc 108 0.538 0.0964 100 0.433 0.519 0.459 ## 10 disttostreams_mean topo 22 0.516 0.0749 20.4 0.269 0.841 0.441 ## 11 Fluorescence_Index doc 27 0.562 0.131 25 0.618 0 0.432 ## 12 percent_Meadows landcov… 22 0.538 0.102 20.4 0.434 0.429 0.432 ## 13 discharge_m2 hydro 52 0.537 0.104 48.1 0.430 0.413 0.425 ## 14 ndvi_raster_mean landcov… 27 0.523 0.0892 25 0.317 0.627 0.410 ## 15 area_km topo 5 0.508 0.0820 4.63 0.200 0.735 0.361 ## 16 aspect_mean_rad topo 39 0.488 0.0643 36.1 0.0510 1 0.336 ## 17 elevabovestreams_me… topo 14 0.482 0.0896 13.0 0 0.621 0.186 6.2.3.5 Generate flow diagram for the top performing model 6.2.3.5.1 Beetlekill forest ## [1] &quot;topo_1&quot; &quot;hydro_1&quot; &quot;landcover_1&quot; &quot;landcover_2&quot; &quot;landcover_3&quot; &quot;doc_1&quot; &quot;doc_2&quot; ## [8] &quot;doc_3&quot; ## Generating the seminr model ## All 33 observations are valid. ## ## Results from package seminr (2.3.4) ## ## Path Coefficients: ## HYDRO LANDCOVER DOC ## R^2 0.100 0.672 0.560 ## AdjR^2 0.040 0.661 0.515 ## TOPO -0.149 -0.820 -0.007 ## LANDCOVER 0.182 . 0.734 ## HYDRO . . 0.027 ## ## Reliability: ## alpha rhoC AVE rhoA ## TOPO 1.000 1.000 1.000 1.000 ## LANDCOVER -9.856 0.222 0.697 0.803 ## HYDRO 1.000 1.000 1.000 1.000 ## DOC 1.000 1.000 1.000 1.000 ## ## Alpha, rhoC, and rhoA should exceed 0.7 while AVE should exceed 0.5 ## Original Est. Bootstrap Mean Bootstrap SD T Stat. 5% CI 95% CI ## TOPO -&gt; LANDCOVER 0.941 0.934 0.057 16.624 0.837 1.022 ## TOPO -&gt; HYDRO 0.298 0.297 0.108 2.751 0.039 0.455 ## TOPO -&gt; DOC 0.617 0.641 0.126 4.898 0.424 0.839 ## LANDCOVER -&gt; HYDRO 0.358 0.400 0.177 2.027 0.131 0.702 ## LANDCOVER -&gt; DOC 0.852 0.824 0.092 9.217 0.655 0.959 ## HYDRO -&gt; DOC 0.253 0.319 0.138 1.837 0.174 0.652 This gives us the confidence intervals of the HTMT ratio. print(indicators) ## $topo ## [1] &quot;aspect_mean_rad&quot; ## ## $hydro ## [1] &quot;discharge_m2&quot; ## ## $landcover ## [1] &quot;percent_Tundra&quot; &quot;percent_Old.Forest&quot; &quot;percent_Beetle.kill&quot; ## ## $doc ## [1] &quot;relative_load_comp_3&quot; &quot;peak_ratioAT&quot; &quot;Fluorescence_Index&quot; 6.2.3.5.2 Regenerating forest ## [1] &quot;topo_1&quot; &quot;hydro_1&quot; &quot;landcover_1&quot; &quot;doc_1&quot; ## Generating the seminr model ## All 33 observations are valid. ## ## Results from package seminr (2.3.4) ## ## Path Coefficients: ## HYDRO LANDCOVER DOC ## R^2 0.070 0.709 0.769 ## AdjR^2 0.008 0.699 0.745 ## TOPO -0.337 0.842 -1.154 ## LANDCOVER 0.476 . 0.355 ## HYDRO . . 0.035 ## ## Reliability: ## alpha rhoC AVE rhoA ## TOPO 1.000 1.000 1.000 1.000 ## LANDCOVER 1.000 1.000 1.000 1.000 ## HYDRO 1.000 1.000 1.000 1.000 ## DOC 1.000 1.000 1.000 1.000 ## ## Alpha, rhoC, and rhoA should exceed 0.7 while AVE should exceed 0.5 ## Original Est. Bootstrap Mean Bootstrap SD T Stat. 5% CI 95% CI ## TOPO -&gt; LANDCOVER 0.842 0.850 0.054 15.691 0.761 0.940 ## TOPO -&gt; HYDRO 0.064 0.141 0.101 0.635 0.015 0.334 ## TOPO -&gt; DOC 0.853 0.864 0.033 25.765 0.805 0.912 ## LANDCOVER -&gt; HYDRO 0.193 0.200 0.116 1.667 0.022 0.400 ## LANDCOVER -&gt; DOC 0.609 0.648 0.081 7.555 0.523 0.789 ## HYDRO -&gt; DOC 0.030 0.086 0.085 0.352 0.006 0.258 This gives us the confidence intervals of the HTMT ratio. print(indicators) ## $topo ## [1] &quot;twi_mean&quot; ## ## $hydro ## [1] &quot;snowpack_3day_avg&quot; ## ## $landcover ## [1] &quot;percent_cut.regenerating&quot; ## ## $doc ## [1] &quot;Fluorescence_Index&quot; 6.2.3.5.3 Old Forest ## [1] &quot;topo_1&quot; &quot;topo_2&quot; &quot;hydro_1&quot; &quot;landcover_1&quot; &quot;doc_1&quot; ## Generating the seminr model ## All 33 observations are valid. ## ## Results from package seminr (2.3.4) ## ## Path Coefficients: ## HYDRO LANDCOVER DOC ## R^2 0.001 0.629 0.706 ## AdjR^2 -0.065 0.617 0.676 ## TOPO -0.014 -0.793 -1.241 ## LANDCOVER -0.049 . -0.619 ## HYDRO . . 0.037 ## ## Reliability: ## alpha rhoC AVE rhoA ## TOPO 0.899 0.952 0.908 0.902 ## LANDCOVER 1.000 1.000 1.000 1.000 ## HYDRO 1.000 1.000 1.000 1.000 ## DOC 1.000 1.000 1.000 1.000 ## ## Alpha, rhoC, and rhoA should exceed 0.7 while AVE should exceed 0.5 ## Original Est. Bootstrap Mean Bootstrap SD T Stat. 5% CI 95% CI ## TOPO -&gt; LANDCOVER 0.840 0.841 0.078 10.820 0.704 0.954 ## TOPO -&gt; HYDRO 0.046 0.171 0.121 0.382 0.034 0.423 ## TOPO -&gt; DOC 0.785 0.826 0.068 11.502 0.726 0.935 ## LANDCOVER -&gt; HYDRO 0.038 0.116 0.088 0.430 0.009 0.291 ## LANDCOVER -&gt; DOC 0.365 0.466 0.283 1.290 0.056 0.874 ## HYDRO -&gt; DOC 0.030 0.086 0.085 0.352 0.006 0.258 This gives us the confidence intervals of the HTMT ratio. 6.2.3.5.4 Beetlekill forest and PARAFAC C3 ## [1] &quot;topo_1&quot; &quot;hydro_1&quot; &quot;landcover_1&quot; &quot;doc_1&quot; ## Generating the seminr model ## All 33 observations are valid. ## ## Results from package seminr (2.3.4) ## ## Path Coefficients: ## HYDRO LANDCOVER DOC ## R^2 0.041 0.712 0.627 ## AdjR^2 -0.023 0.703 0.588 ## TOPO 0.367 0.844 -0.633 ## LANDCOVER -0.359 . -0.177 ## HYDRO . . -0.052 ## ## Reliability: ## alpha rhoC AVE rhoA ## TOPO 1.000 1.000 1.000 1.000 ## LANDCOVER 1.000 1.000 1.000 1.000 ## HYDRO 1.000 1.000 1.000 1.000 ## DOC 1.000 1.000 1.000 1.000 ## ## Alpha, rhoC, and rhoA should exceed 0.7 while AVE should exceed 0.5 ## Original Est. Bootstrap Mean Bootstrap SD T Stat. 5% CI 95% CI ## TOPO -&gt; LANDCOVER 0.844 0.847 0.040 20.957 0.777 0.908 ## TOPO -&gt; HYDRO 0.064 0.141 0.101 0.635 0.015 0.334 ## TOPO -&gt; DOC 0.786 0.772 0.080 9.817 0.631 0.887 ## LANDCOVER -&gt; HYDRO 0.049 0.143 0.122 0.404 0.011 0.396 ## LANDCOVER -&gt; DOC 0.708 0.709 0.076 9.374 0.574 0.823 ## HYDRO -&gt; DOC 0.084 0.134 0.092 0.913 0.014 0.300 This gives us the confidence intervals of the HTMT ratio. print(indicators) ## $topo ## [1] &quot;twi_mean&quot; ## ## $hydro ## [1] &quot;snowpack_3day_avg&quot; ## ## $landcover ## [1] &quot;percent_Beetle.kill&quot; ## ## $doc ## [1] &quot;relative_load_comp_3&quot; 6.2.4 Model 4: Low flows - HUMIC -WO/NUTRIENTS (AUTOMATED) 6.2.4.1 Indicator list These will be the indicators that will be randomly selected from during automation. Select labile or humic DOC responses here model_df &lt;- data.frame(matrix(ncol = 0, nrow = nrow(filtered_df))) indicators &lt;- list( topo = c( &quot;disttostreams_mean&quot;, &#39;twi_mean&#39;, &#39;area_km&#39;, &quot;elevabovestreams_mean&quot;, &quot;aspect_mean_rad&quot;), hydro = c(&quot;discharge_m2&quot;), landcover = c(&quot;percent_Beetle.kill&quot;, &quot;percent_Meadows&quot;,&quot;percent_Old.Forest&quot;,&quot;percent_cut.regenerating&quot;, &quot;percent_Tundra&quot; ,&quot;ndvi_raster_mean&quot;), doc = c(&quot;relative_load_comp_1&quot;, &quot;relative_load_comp_2&quot;, &quot;norm_PARAF_c1&quot;, &quot;norm_PARAF_c2&quot;, &quot;peak_T_275.340&quot;, &quot;Fluorescence_Index&quot;, &quot;SUVA254&quot;, &quot;peak_ratioAT&quot;, &quot;peak_ratioCT&quot;) ) 6.2.4.2 Run the function written in .R script ## [1] &quot;20000 run winner: &quot; ## [1] 0.6039023 ## $topo ## [1] &quot;twi_mean&quot; ## ## $hydro ## [1] &quot;snowpack_3day_avg&quot; ## ## $landcover ## [1] &quot;percent_cut.regenerating&quot; ## ## $doc ## [1] &quot;peak_ratioCT&quot; &quot;relative_load_comp_2&quot; &quot;SUVA254&quot; Or we can find the highest performing model where some value is specified for the ‘DOC’ response ## Best R^2 for DOC: 0.5316313 ## Selected DOC response: ## [1] &quot;relative_load_comp_1&quot; ## Sampled indicators for best model: ## $topo ## [1] &quot;twi_mean&quot; ## ## $hydro ## [1] &quot;snowpack_3day_avg&quot; ## ## $landcover ## [1] &quot;percent_Beetle.kill&quot; &quot;ndvi_raster_mean&quot; &quot;percent_cut.regenerating&quot; ## ## $doc ## [1] &quot;relative_load_comp_1&quot; &quot;relative_load_comp_2&quot; &quot;peak_T_275.340&quot; 6.2.4.3 Visualizing all selected results (r2 of DOC &gt;0.4) 6.2.4.3.1 Indicator frequency 6.2.4.3.2 R2 distribution 6.2.4.3.3 Combine these two ideas: Create the dataframe 6.2.4.4 Visualizing specific DOC results (r2 of DOC &gt;0.4) 6.2.4.4.1 Indicator frequency 6.2.4.4.2 R2 distribution 6.2.4.4.3 Combine these two ideas: Create the dataframe 6.2.4.5 Generate flow diagram for the top performing model ## [1] &quot;topo_1&quot; &quot;hydro_1&quot; &quot;landcover_1&quot; &quot;doc_1&quot; &quot;doc_2&quot; &quot;doc_3&quot; ## Generating the seminr model ## All 64 observations are valid. ## ## Results from package seminr (2.3.4) ## ## Path Coefficients: ## HYDRO LANDCOVER DOC ## R^2 0.025 0.564 0.595 ## AdjR^2 -0.007 0.557 0.575 ## TOPO -0.135 0.751 0.781 ## LANDCOVER -0.031 . -0.013 ## HYDRO . . -0.005 ## ## Reliability: ## alpha rhoC AVE rhoA ## TOPO 1.000 1.000 1.000 1.000 ## LANDCOVER 1.000 1.000 1.000 1.000 ## HYDRO 1.000 1.000 1.000 1.000 ## DOC 0.777 0.876 0.713 0.878 ## ## Alpha, rhoC, and rhoA should exceed 0.7 while AVE should exceed 0.5 ## Original Est. Bootstrap Mean Bootstrap SD T Stat. 5% CI 95% CI ## TOPO -&gt; LANDCOVER 0.751 0.756 0.090 8.324 0.592 0.879 ## TOPO -&gt; HYDRO 0.158 0.212 0.118 1.346 0.122 0.530 ## TOPO -&gt; DOC 0.862 0.858 0.063 13.581 0.748 0.956 ## LANDCOVER -&gt; HYDRO 0.132 0.151 0.046 2.904 0.093 0.240 ## LANDCOVER -&gt; DOC 0.647 0.647 0.090 7.167 0.494 0.790 ## HYDRO -&gt; DOC 0.141 0.209 0.175 0.806 0.072 0.679 This gives us the confidence intervals of the HTMT ratio. print(indicators) ## $topo ## [1] &quot;twi_mean&quot; ## ## $hydro ## [1] &quot;discharge_m2&quot; ## ## $landcover ## [1] &quot;percent_cut.regenerating&quot; ## ## $doc ## [1] &quot;peak_ratioCT&quot; &quot;relative_load_comp_2&quot; &quot;SUVA254&quot; 6.2.5 Model 5: Low flows - LABILE -WO/NUTRIENTS (AUTOMATED) 6.2.5.1 Indicator list These will be the indicators that will be randomly selected from during automation. Select labile or humic DOC responses here model_df &lt;- data.frame(matrix(ncol = 0, nrow = nrow(filtered_df))) indicators &lt;- list( topo = c( &quot;disttostreams_mean&quot;, &#39;twi_mean&#39;, &#39;area_km&#39;, &quot;elevabovestreams_mean&quot;, &quot;aspect_mean_rad&quot;), hydro = c(&quot;discharge_m2&quot;), landcover = c(&quot;percent_Beetle.kill&quot;, &quot;percent_Meadows&quot;,&quot;percent_Old.Forest&quot;,&quot;percent_cut.regenerating&quot;,&quot;percent_Tundra&quot; ,&quot;ndvi_raster_mean&quot;), doc = c(&quot;relative_load_comp_3&quot;, &quot;norm_PARAF_c3&quot;, &quot;peak_T_275.340&quot;, &quot;Fluorescence_Index&quot;, &quot;SUVA254&quot;, &quot;peak_ratioAT&quot;, &quot;peak_ratioCT&quot;) ) 6.2.5.2 Run the function written in .R script ## [1] &quot;20000 run winner: &quot; ## [1] 0.5984462 ## $topo ## [1] &quot;aspect_mean_rad&quot; ## ## $hydro ## [1] &quot;discharge_m2&quot; ## ## $landcover ## [1] &quot;percent_Tundra&quot; &quot;ndvi_raster_mean&quot; ## ## $doc ## [1] &quot;peak_ratioCT&quot; Or we can find the highest performing model where some value is specified for the ‘DOC’ response ## Best R^2 for DOC: 0.4839981 ## Selected DOC response: ## [1] &quot;relative_load_comp_3&quot; ## Sampled indicators for best model: ## $topo ## [1] &quot;twi_mean&quot; ## ## $hydro ## [1] &quot;discharge_m2&quot; ## ## $landcover ## [1] &quot;percent_Tundra&quot; &quot;ndvi_raster_mean&quot; &quot;percent_cut.regenerating&quot; ## ## $doc ## [1] &quot;relative_load_comp_3&quot; &quot;norm_PARAF_c3&quot; &quot;Fluorescence_Index&quot; 6.2.5.3 Visualizing all selected results (r2 of DOC &gt;0.4) 6.2.5.3.1 Indicator frequency 6.2.5.3.2 R2 distribution 6.2.5.3.3 Combine these two ideas: Create the dataframe 6.2.5.4 Visualizing specific DOC results (r2 of DOC &gt;0.4) 6.2.5.4.1 Indicator frequency 6.2.5.4.2 R2 distribution 6.2.5.4.3 Combine these two ideas: Create the dataframe 6.2.5.5 Generate flow diagram for the top performing model ## [1] &quot;topo_1&quot; &quot;hydro_1&quot; &quot;landcover_1&quot; &quot;landcover_2&quot; &quot;doc_1&quot; &quot;doc_2&quot; &quot;doc_3&quot; ## Generating the seminr model ## All 64 observations are valid. ## ## Results from package seminr (2.3.4) ## ## Path Coefficients: ## HYDRO LANDCOVER DOC ## R^2 0.202 0.664 0.365 ## AdjR^2 0.175 0.658 0.333 ## TOPO 0.432 0.815 -0.413 ## LANDCOVER -0.725 . -0.239 ## HYDRO . . -0.148 ## ## Reliability: ## alpha rhoC AVE rhoA ## TOPO 1.000 1.000 1.000 1.000 ## LANDCOVER 0.882 0.944 0.894 0.888 ## HYDRO 1.000 1.000 1.000 1.000 ## DOC 1.000 1.000 1.000 1.000 ## ## Alpha, rhoC, and rhoA should exceed 0.7 while AVE should exceed 0.5 ## Original Est. Bootstrap Mean Bootstrap SD T Stat. 5% CI 95% CI ## TOPO -&gt; LANDCOVER 0.864 0.862 0.058 14.854 0.750 0.940 ## TOPO -&gt; HYDRO 0.158 0.211 0.118 1.338 0.122 0.521 ## TOPO -&gt; DOC 0.585 0.581 0.111 5.272 0.381 0.743 ## LANDCOVER -&gt; HYDRO 0.403 0.433 0.092 4.402 0.306 0.593 ## LANDCOVER -&gt; DOC 0.549 0.546 0.106 5.184 0.360 0.701 ## HYDRO -&gt; DOC 0.006 0.083 0.158 0.039 0.002 0.521 This gives us the confidence intervals of the HTMT ratio. print(indicators) ## $topo ## [1] &quot;twi_mean&quot; ## ## $hydro ## [1] &quot;discharge_m2&quot; ## ## $landcover ## [1] &quot;percent_Beetle.kill&quot; &quot;ndvi_raster_mean&quot; ## ## $doc ## [1] &quot;relative_load_comp_3&quot; &quot;norm_PARAF_c3&quot; &quot;Fluorescence_Index&quot; "],["final-publishable-pngs.html", "Chapter 7 Final publishable pngs", " Chapter 7 Final publishable pngs Addendum Figures 7.0.1 1. PARAFAC results summary figures: Emission-Excitation matrices for the 3 components identified by the 3 component PARAFAC model. Components 1 and 2 correspond with peaks for humic components, while component 3 is protein-like. 7.0.2 2. Relative loadings Relative loadings for each sample (i.e., loading for each component/total loading for the sample in the 3 component model). This tells us how much of each component contributes to the total fluorescence of that particular sample. Final figures Exploration of DOC concentrations across watersheds DOC temporal patterns DOC bioavailability - EEMS indices Correlations between PARAFAC componet proportions and EEMs indices DOC composition PARAFAC PLS_SEM This script contains recreations of models that explain the most variability in labile and humic DOM. The intent is to generate images that are quickly interpretable for posters, presentations or papers. AGU Model 1: Figure: PLS-SEM models depicting the effects of four variables on the humic fraction of fluorescing DOM in high flows (a) and low flows (b). The beta coefficients (β) in each relationship indicates the strength of the relationship between latent variables. Negative relationships are shown in red, positive relationships are printed in black, with significant relationships in bold text and asterisks to indicate level of significance. A negative β indicates that as the latent variable increases the dependent latent variable decreases. The coefficient of determination (R2) represents the proportion of variance in the latent variable explained by the variables (latent or observed). Higher R2 values indicate a better ability of the model to explain the variance in the latent variable. In this high-flow to low-flow comparison, we see that topography has a strong reinforcing effect on landcover composition, which in this model is characterized by the % coverage of harvested and regenerating forest, and the % of beetle kill affected forest. In high flows, the humic fraction of fluorescing DOM is strong and positive, indicating that as the % of beetle kill and regenerating forest increase, humic fractions increase. In low flows,the humic fraction of DOM decreases as NO3- concentration in the water sample increases. This could be an indication that NO3- is being allochthonously utilized by microbial communities to oxidize and polymerize carbon (increasing humic fractions) rather than being transported to the stream channel. AGU Model 2: Figure: PLS-SEM models depicting the effects of four variables on the protein-like fraction of fluorescing DOM in high flows (a) and low flows (b). The beta coefficients (β) in each relationship indicates the strength of the relationship between latent variables. In this high-flow to low-flow comparison, we see that topography has a strong reinforcing effect on landcover composition, which in this model is characterized by the % coverage of harvested and regenerating forest, and the % of beetle kill affected forest. In high flows, the protein-like (labile) fraction of fluorescing DOM is strong and negative, indicating that as the % of beetle kill and regenerating forest decrease, labile fractions increase. In low flows, NO3- has a significant positive influence on the labile fraction, as the labile fraction of DOM increases as NO3- concentration in the water sample increases. Nutrient Free models Low Flows: indicators &lt;- list( topo = c(“twi_mean”), hydro = c(“discharge_m2”), landcover = c(“percent_cut.regenerating”), doc = c(“peak_ratioCT”, “relative_load_comp_2”, “SUVA254”) ) High Flows: indicators &lt;- list( topo = c(“twi_mean”), hydro = c(“discharge_m2”), landcover = c(“percent_Tundra”), doc = c( “Fluorescence_Index”) ) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
